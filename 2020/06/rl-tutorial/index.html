<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="generator" content="Hugo 0.69.0" />
  <link rel="canonical" href="https://dennislblog.github.io/cnblog/2020/06/rl-tutorial/">

  

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#000000">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="https://dennislblog.github.io/cnblog/css/prism.css" media="none" onload="this.media='all';">
  <link rel="stylesheet" href="https://dennislblog.github.io/cnblog/css/syntax.css" media="none" onload="this.media='all';">


  
  
  <link rel="stylesheet" type="text/css" href="https://dennislblog.github.io/cnblog/css/styles.css">

  <style id="inverter" media="none">
    .intro-and-nav, .main-and-footer { filter: invert(100%) }
    * { background-color: inherit }
    img:not([src*=".svg"]), .colors, iframe, .demo-container { filter: invert(100%) }
  </style>

  
  
  <title>Reinforcement Learning Tutorial | My Site Title</title>
  

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"]},
    },
    "HTML-CSS": {
    	scale: 80,
    	styles: {
    		".MathJax": {color: "rgb(91, 58, 17)",}
    	},
    },
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>




</head>

  <body>
    <a href="#main">skip to content</a>
    <svg style="display: none">
  <symbol id="bookmark" viewBox="0 0 40 50">
   <g transform="translate(2266 3206.2)">
    <path style="stroke:currentColor;stroke-width:3.2637;fill:none" d="m-2262.2-3203.4-.2331 42.195 16.319-16.318 16.318 16.318.2331-42.428z"/>
   </g>
  </symbol>

  <symbol id="w3c" viewBox="0 0 127.09899 67.763">
   <text font-size="83" style="font-size:83px;font-family:Trebuchet;letter-spacing:-12;fill-opacity:0" letter-spacing="-12" y="67.609352" x="-26.782778">W3C</text>
   <text font-size="83" style="font-size:83px;font-weight:bold;font-family:Trebuchet;fill-opacity:0" y="67.609352" x="153.21722" font-weight="bold">SVG</text>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m33.695.377 12.062 41.016 12.067-41.016h8.731l-19.968 67.386h-.831l-12.48-41.759-12.479 41.759h-.832l-19.965-67.386h8.736l12.061 41.016 8.154-27.618-3.993-13.397h8.737z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m91.355 46.132c0 6.104-1.624 11.234-4.862 15.394-3.248 4.158-7.45 6.237-12.607 6.237-3.882 0-7.263-1.238-10.148-3.702-2.885-2.47-5.02-5.812-6.406-10.022l6.82-2.829c1.001 2.552 2.317 4.562 3.953 6.028 1.636 1.469 3.56 2.207 5.781 2.207 2.329 0 4.3-1.306 5.909-3.911 1.609-2.606 2.411-5.738 2.411-9.401 0-4.049-.861-7.179-2.582-9.399-1.995-2.604-5.129-3.912-9.397-3.912h-3.327v-3.991l11.646-20.133h-14.062l-3.911 6.655h-2.493v-14.976h32.441v4.075l-12.31 21.217c4.324 1.385 7.596 3.911 9.815 7.571 2.22 3.659 3.329 7.953 3.329 12.892z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.21 0 1.414 8.6-5.008 9.583s-1.924-4.064-5.117-6.314c-2.693-1.899-4.447-2.309-7.186-1.746-3.527.73-7.516 4.938-9.258 10.13-2.084 6.21-2.104 9.218-2.178 11.978-.115 4.428.58 7.043.58 7.043s-3.04-5.626-3.011-13.866c.018-5.882.947-11.218 3.666-16.479 2.404-4.627 5.954-7.404 9.114-7.728 3.264-.343 5.848 1.229 7.841 2.938 2.089 1.788 4.213 5.698 4.213 5.698l4.94-9.837z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.82 48.674s-2.208 3.957-3.589 5.48c-1.379 1.524-3.849 4.209-6.896 5.555-3.049 1.343-4.646 1.598-7.661 1.306-3.01-.29-5.807-2.032-6.786-2.764-.979-.722-3.486-2.864-4.897-4.854-1.42-2-3.634-5.995-3.634-5.995s1.233 4.001 2.007 5.699c.442.977 1.81 3.965 3.749 6.572 1.805 2.425 5.315 6.604 10.652 7.545 5.336.945 9.002-1.449 9.907-2.031.907-.578 2.819-2.178 4.032-3.475 1.264-1.351 2.459-3.079 3.116-4.108.487-.758 1.276-2.286 1.276-2.286l-1.276-6.644z"/>
  </symbol>

  <symbol id="tag" viewBox="0 0 177.16535 177.16535">
    <g transform="translate(0 -875.2)">
     <path style="fill-rule:evenodd;stroke-width:0;fill:currentColor" d="m159.9 894.3-68.79 8.5872-75.42 77.336 61.931 60.397 75.429-76.565 6.8495-69.755zm-31.412 31.835a10.813 10.813 0 0 1 1.8443 2.247 10.813 10.813 0 0 1 -3.5174 14.872l-.0445.0275a10.813 10.813 0 0 1 -14.86 -3.5714 10.813 10.813 0 0 1 3.5563 -14.863 10.813 10.813 0 0 1 13.022 1.2884z"/>
    </g>
  </symbol>

  <symbol id="balloon" viewBox="0 0 141.73228 177.16535">
   <g transform="translate(0 -875.2)">
    <g>
     <path style="fill:currentColor" d="m68.156 882.83-.88753 1.4269c-4.9564 7.9666-6.3764 17.321-5.6731 37.378.36584 10.437 1.1246 23.51 1.6874 29.062.38895 3.8372 3.8278 32.454 4.6105 38.459 4.6694-.24176 9.2946.2879 14.377 1.481 1.2359-3.2937 5.2496-13.088 8.886-21.623 6.249-14.668 8.4128-21.264 10.253-31.252 1.2464-6.7626 1.6341-12.156 1.4204-19.764-.36325-12.93-2.1234-19.487-6.9377-25.843-2.0833-2.7507-6.9865-7.6112-7.9127-7.8436-.79716-.20019-6.6946-1.0922-6.7755-1.0248-.02213.0182-5.0006-.41858-7.5248-.22808l-2.149-.22808h-3.3738z"/>
     <path style="fill:currentColor" d="m61.915 883.28-3.2484.4497c-1.7863.24724-3.5182.53481-3.8494.63994-2.4751.33811-4.7267.86957-6.7777 1.5696-.28598 0-1.0254.20146-2.3695.58589-5.0418 1.4418-6.6374 2.2604-8.2567 4.2364-6.281 7.6657-11.457 18.43-12.932 26.891-1.4667 8.4111.71353 22.583 5.0764 32.996 3.8064 9.0852 13.569 25.149 22.801 37.517 1.3741 1.841 2.1708 2.9286 2.4712 3.5792 3.5437-1.1699 6.8496-1.9336 10.082-2.3263-1.3569-5.7831-4.6968-21.86-6.8361-33.002-.92884-4.8368-2.4692-14.322-3.2452-19.991-.68557-5.0083-.77707-6.9534-.74159-15.791.04316-10.803.41822-16.162 1.5026-21.503 1.4593-5.9026 3.3494-11.077 6.3247-15.852z"/>
     <path style="fill:currentColor" d="m94.499 885.78c-.10214-.0109-.13691 0-.0907.0409.16033.13489 1.329 1.0675 2.5976 2.0723 6.7003 5.307 11.273 14.568 12.658 25.638.52519 4.1949.24765 14.361-.5059 18.523-2.4775 13.684-9.7807 32.345-20.944 53.519l-3.0559 5.7971c2.8082.76579 5.7915 1.727 8.9926 2.8441 11.562-11.691 18.349-19.678 24.129-28.394 7.8992-11.913 11.132-20.234 12.24-31.518.98442-10.02-1.5579-20.876-6.7799-28.959-.2758-.4269-.57803-.86856-.89617-1.3166-3.247-6.13-9.752-12.053-21.264-16.131-2.3687-.86369-6.3657-2.0433-7.0802-2.1166z"/>
     <path style="fill:currentColor" d="m32.52 892.22c-.20090-.13016-1.4606.81389-3.9132 2.7457-11.486 9.0476-17.632 24.186-16.078 39.61.79699 7.9138 2.4066 13.505 5.9184 20.562 5.8577 11.77 14.749 23.219 30.087 38.74.05838.059.12188.1244.18052.1838 1.3166-.5556 2.5965-1.0618 3.8429-1.5199-.66408-.32448-1.4608-1.3297-3.8116-4.4602-5.0951-6.785-8.7512-11.962-13.051-18.486-5.1379-7.7948-5.0097-7.5894-8.0586-13.054-6.2097-11.13-8.2674-17.725-8.6014-27.563-.21552-6.3494.13041-9.2733 1.775-14.987 2.1832-7.5849 3.9273-10.986 9.2693-18.07 1.7839-2.3656 2.6418-3.57 2.4409-3.7003z"/>
     <path style="fill:currentColor" d="m69.133 992.37c-6.2405.0309-12.635.76718-19.554 2.5706 4.6956 4.7759 9.935 10.258 12.05 12.625l4.1272 4.6202h11.493l3.964-4.4516c2.0962-2.3541 7.4804-7.9845 12.201-12.768-8.378-1.4975-16.207-2.6353-24.281-2.5955z"/>
     <rect style="stroke-width:0;fill:currentColor" ry="2.0328" height="27.746" width="22.766" y="1017.7" x="60.201"/>
    </g>
   </g>
  </symbol>

  <symbol id="info" viewBox="0 0 41.667 41.667">
   <g transform="translate(-37.035 -1004.6)">
    <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m76.25 1030.2a18.968 18.968 0 0 1 -23.037 13.709 18.968 18.968 0 0 1 -13.738 -23.019 18.968 18.968 0 0 1 23.001 -13.768 18.968 18.968 0 0 1 13.798 22.984"/>
    <g transform="matrix(1.1146 0 0 1.1146 -26.276 -124.92)">
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m75.491 1039.5v-8.7472"/>
     <path style="stroke-width:0;fill:currentColor" transform="scale(-1)" d="m-73.193-1024.5a2.3719 2.3719 0 0 1 -2.8807 1.7142 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
   </g>
  </symbol>

  <symbol id="warning" viewBox="0 0 48.430474 41.646302">
    <g transform="translate(-1.1273 -1010.2)">
     <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:4.151;fill:none" d="m25.343 1012.3-22.14 37.496h44.28z"/>
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:4.1512;fill:none" d="m25.54 1027.7v8.7472"/>
     <path style="stroke-width:0;fill:currentColor" d="m27.839 1042.8a2.3719 2.3719 0 0 1 -2.8807 1.7143 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
  </symbol>

  <symbol id="menu" viewBox="0 0 50 50">
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="0" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="20" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="40" x="0"/>
   </symbol>

   <symbol id="link" viewBox="0 0 50 50">
    <g transform="translate(0 -1002.4)">
     <g transform="matrix(.095670 0 0 .095670 2.3233 1004.9)">
      <g>
       <path style="stroke-width:0;fill:currentColor" d="m452.84 192.9-128.65 128.65c-35.535 35.54-93.108 35.54-128.65 0l-42.881-42.886 42.881-42.876 42.884 42.876c11.845 11.822 31.064 11.846 42.886 0l128.64-128.64c11.816-11.831 11.816-31.066 0-42.9l-42.881-42.881c-11.822-11.814-31.064-11.814-42.887 0l-45.928 45.936c-21.292-12.531-45.491-17.905-69.449-16.291l72.501-72.526c35.535-35.521 93.136-35.521 128.64 0l42.886 42.881c35.535 35.523 35.535 93.141-.001 128.66zm-254.28 168.51-45.903 45.9c-11.845 11.846-31.064 11.817-42.881 0l-42.884-42.881c-11.845-11.821-11.845-31.041 0-42.886l128.65-128.65c11.819-11.814 31.069-11.814 42.884 0l42.886 42.886 42.876-42.886-42.876-42.881c-35.54-35.521-93.113-35.521-128.65 0l-128.65 128.64c-35.538 35.545-35.538 93.146 0 128.65l42.883 42.882c35.51 35.54 93.11 35.54 128.65 0l72.496-72.499c-23.956 1.597-48.092-3.784-69.474-16.283z"/>
      </g>
     </g>
    </g>
  </symbol>

  <symbol id="doc" viewBox="0 0 35 45">
   <g transform="translate(-147.53 -539.83)">
    <path style="stroke:currentColor;stroke-width:2.4501;fill:none" d="m149.38 542.67v39.194h31.354v-39.194z"/>
    <g style="stroke-width:25" transform="matrix(.098003 0 0 .098003 133.69 525.96)">
     <path d="m220 252.36h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path style="stroke:currentColor;stroke-width:25;fill:none" d="m220 409.95h200"/>
     <path d="m220 488.74h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path d="m220 331.15h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
    </g>
   </g>
 </symbol>

 <symbol id="tick" viewBox="0 0 177.16535 177.16535">
  <g transform="translate(0 -875.2)">
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="155" width="40" y="702.99" x="556.82"/>
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="40" width="90.404" y="817.99" x="506.42"/>
  </g>
 </symbol>
</svg>

    <div class="wrapper">
      <header class="intro-and-nav" role="banner">
  <div>
    <div class="intro">
      <a class="logo" href="/" aria-label="My Site Title home page">
        <img src="https://dennislblog.github.io/cnblog/pics/logo.svg" alt="">
      </a>
      <p class="library-desc">
        
        Hello, you all
        
      </p>
    </div>
    <nav id="patterns-nav" class="patterns" role="navigation">
  <h2 class="vh">Main navigation</h2>
  <button id="menu-button" aria-expanded="false">
    <svg viewBox="0 0 50 50" aria-hidden="true" focusable="false">
      <use xlink:href="#menu"></use>
    </svg>
    Menu
  </button>
  
  <ul id="patterns-list">
  
    <li class="pattern">
      
      
      
      
      <a href="/cnblog/post/" aria-current="page">
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use xlink:href="#bookmark"></use>
        </svg>
        <span class="text">Blog</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/cnblog/tags/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use xlink:href="#bookmark"></use>
        </svg>
        <span class="text">Tags</span>
      </a>
    </li>
  
  </ul>
</nav>
    
    



  <hr>
  <nav class="patterns" aria-labelledby="toc-heading">
    <h4 id="toc-heading" style="margin-bottom: 1em">Table of contents</h4> 
    <ol>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0%e6%a6%82%e8%bf%b0" style="padding-left: 0rem">
            强化学习概述
          </a>
        </li>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#dqn-%e5%8f%8a%e5%85%b6-%e6%94%b9%e8%bf%9b" style="padding-left: 0rem">
            DQN 及其 改进
          </a>
        </li>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#policy-gradient" style="padding-left: 0rem">
            Policy Gradient
          </a>
        </li>
      
    </ol>
  </nav>





    
  </div>
</header>
      <div class="main-and-footer">
        <div>
          
  <main id="main">
    <h1>
      <svg class="bookmark-icon" aria-hidden="true" viewBox="0 0 40 50" focusable="false">
        <use xlink:href="#bookmark"></use>
      </svg>
      Reinforcement Learning Tutorial
    </h1>

    <div class="date">
      
      
      <strong aria-hidden="true">Publish date: </strong>Sunday, June 7, 2020
      
        
      
    </div>

    
      <div class="tags">
        <strong aria-hidden="true">Tags: </strong>
        <ul aria-label="tags">
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use xlink:href="#tag"></use>
              </svg>
              
              <a href="https://dennislblog.github.io/cnblog/tags/rl/">RL</a>
            </li>
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use xlink:href="#tag"></use>
              </svg>
              
              <a href="https://dennislblog.github.io/cnblog/tags/tutorial/">Tutorial</a>
            </li>
          
        </ul>
      </div>
    
    <p>review the history of reinforcement learning algorithms developed in recent years</p>
<h2 id="强化学习概述">强化学习概述</h2>
<p>




<figure role="group">
    <a href=" pics/rl-method.png" class="img-link">
        <img src="pics/rl-method.png" width=100% title="模型概述">
    </a>
    <figcaption>
        深度强化学习关键论文
    </figcaption>
</figure></p>
<h2 id="dqn-及其-改进">DQN 及其 改进</h2>
<ul>
<li>
<p>2013年<code>NIPS</code>发表 deep Q learning, 其损失函数(蓝色部分是<code>target</code>，绿色部分是模型<code>prediction</code>)为 
$$L=E[(\color{blue}{r+\gamma \max_{a&rsquo;}Q_w(s&rsquo;,a&rsquo;)}-\color{green}{Q_w(s,a)})^2]$$</p>
</li>
<li>
<p>2015年<code>DeepMind</code>在<code>Nature</code>上单独使用一个<code>target network</code>($Q_{w^-}$)，避免训练波动太大，其损失函数为 
$$L=E[(\color{blue}{r+\gamma \max_{a&rsquo;}Q_{w^-}(s&rsquo;,a&rsquo;)}-\color{green}{Q_w(s,a)})^2]$$</p>
</li>
<li>
<p>2015年<code>DeepMind</code>在<code>NIPS</code>发表 <a href="https://papers.nips.cc/paper/3964-double-q-learning.pdf">double Q learning</a>, 论文解读见<a href="https://mp.weixin.qq.com/s/NkWj1bV7uMjACxAvxhPJXw">这里</a>。为了避免<code>target Q</code>总是被高估<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>，取<code>target Q</code>里非最优的<code>action</code> 
$$L=E[(\color{blue}{r+\gamma Q_{w^-}(s&rsquo;,\color{red}{\mathop{\arg\max}_{a&rsquo;}Q_w(s&rsquo;,a&rsquo;)})}-\color{green}{Q_w(s,a)})^2]$$</p>
<ul>
<li>采样优先级：根据<code>target Q</code>和 <code>current Q</code>的差值确定采样概率，详细解释和代码见<a href="https://mp.weixin.qq.com/s/qPk3hbFDcuWIanddvBAUNA">这里</a></li>
<li><code>Dueling Network</code>: 把<code>Q network</code>拆分成两个，一个是和<code>action prediction</code>无关的<code>value function</code> $V_\mu(s)$ 和 与之相关的<code>action value</code> $A_\eta(s,a)$ 然后把这两个函数预测值加起来得到$Q(s,a)$</li>
</ul>
</li>
<li>
<p>2016年<code>ICML</code>上发表的 <a href="http://www.jmlr.org/proceedings/papers/v48/gu16.pdf">continuous Q learning</a> 不同于<code>actor-critic</code>对<code>action-value</code>分别评估的方法，用一个函数对<code>state</code>输出三个值$V\in R$,$\mu\in R^n$,$L_0 \in R^{nxn}$，通过<code>Cholesky</code>分解重构<code>advantage value</code>和 <code>Q value</code> 

<div class="expandable-section">
  
    <button aria-expanded="false" data-expands="js-expandable-0261c20df9cbb58760da3a3d7e352203">
      <span class="expandable-label">算法详细</span>
      <svg aria-hidden="true" focusable="false" viewBox="0 0 70.866142 70.866141">
        <g transform="translate(0 -981.5)">
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="60" width="9.8985" y="987.36" x="30.051" class="up-strut" />
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="10" width="60" y="1012.4" x="5"/>
        </g>
      </svg>
    </button>
  
  <div id="js-expandable-0261c20df9cbb58760da3a3d7e352203" hidden>
    <img src="pics/naf.png" alt="ff" class="center">
<p>上图代表<code>NAF</code>的模型结构图，根据输入状态-动作<code>(s,a)</code>计算相对应的<code>Q</code>值用于反向求导
$$A(s,\mu)=-\frac{1}{2}\langle a-\mu_\theta(s)\rangle^T P_L(s)\langle a-\mu_\theta(s)\rangle$$</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">s</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="o">//</span> <span class="nb">input</span> <span class="n">embedder</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn0</span><span class="p">(</span><span class="n">s</span><span class="p">);</span> <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="o">//</span> <span class="n">output</span> <span class="n">value</span><span class="p">,</span> <span class="n">action</span> <span class="n">mean</span> <span class="ow">and</span> <span class="n">L</span> <span class="n">corner</span> <span class="n">matrix</span>
    <span class="n">V</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="n">a</span><span class="p">:</span>
        <span class="n">num_outputs</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">L</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">,</span> <span class="n">num_outputs</span><span class="p">)</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">L</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">tril_mask</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">L</span><span class="p">)</span> \
            <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">L</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">diag_mask</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">L</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">a_mu</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">a_mu</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">P</span><span class="p">),</span> <span class="n">a_mu</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">Q</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="n">V</span>
    <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">V</span>
</code></pre></td></tr></table>
</div>
</div><p>其中$\mu$表示预测策略的期望值，通过增加<code>action noise</code>输出决策行为</p>

  </div>
</div>
</p>
</li>
<li>
<p>2017年<code>ICML</code>上发表的 <a href="https://arxiv.org/pdf/1707.06887.pdf">distributional/categorical reinforcement learning</a> 不同于传统<code>Q learning</code>逼近价值期望，他们则希望逼近价值分布<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>。<code>DQN</code>输出<code>N</code>个动作对应的值，<code>Categorical DQN</code>则输出<code>N x M</code>的矩阵表示<code>N</code>个动作在<code>M</code>个价值分布上的概率</p>
</li>
<li>
<p>2017年<code>AAAI</code>上发表的 <a href="https://arxiv.org/pdf/1710.02298.pdf">Rainbow: Combining improvements in deep reinforcement learning</a> 通过整合6种已经发表的<code>DQN</code>改进方法提高训练效果，详细代码请见<a href="https://github.com/Curt-Park/rainbow-is-all-you-need">这里</a>

<div class="expandable-section">
  
    <button aria-expanded="false" data-expands="js-expandable-89ca8b2c61d8ed687d695e15a7dcc18c">
      <span class="expandable-label">代码简介</span>
      <svg aria-hidden="true" focusable="false" viewBox="0 0 70.866142 70.866141">
        <g transform="translate(0 -981.5)">
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="60" width="9.8985" y="987.36" x="30.051" class="up-strut" />
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="10" width="60" y="1012.4" x="5"/>
        </g>
      </svg>
    </button>
  
  <div id="js-expandable-89ca8b2c61d8ed687d695e15a7dcc18c" hidden>
    <div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python">    <span class="s2">&#34;&#34;&#34;1. Prioritized replay Buffer with N-step collection of rewards based on TD error&#34;&#34;&#34;</span>
    <span class="k">class</span> <span class="nc">PrioritizedReplayBuffer</span><span class="p">(</span><span class="n">ReplayBuffer</span><span class="p">):</span>
        <span class="s2">&#34;&#34;&#34; transition = (obs, act, rew, next_obs, done) &#34;&#34;&#34;</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_step</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_step_buffer</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">n_step</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sum_tree</span> <span class="o">=</span> <span class="n">SumSegmentTree</span><span class="p">(</span><span class="n">tree_capacity</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">min_tree</span> <span class="o">=</span> <span class="n">MinSegmentTree</span><span class="p">(</span><span class="n">tree_capacity</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_get_n_step_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">buffer</span><span class="p">):</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">rew</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="n">n_step_buffer</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">transition</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">buffer</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">n_o</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">transition</span>
                <span class="n">rew</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">rew</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">d</span><span class="p">)</span>
                <span class="n">next_obs</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_o</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="k">if</span> <span class="n">d</span> <span class="k">else</span> <span class="p">(</span><span class="n">next_obs</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">rew</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">done</span>

        <span class="k">def</span> <span class="nf">_calculate_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
            <span class="s2">&#34;&#34;&#34; calculate the weight of the experience at idx.&#34;&#34;&#34;</span>
            <span class="n">p_min</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_tree</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum_tree</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">max_weight</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_min</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="n">beta</span><span class="p">)</span>
            <span class="n">p_sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum_tree</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sum_tree</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="p">(</span><span class="n">p_sample</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="n">beta</span><span class="p">)</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">/</span> <span class="n">max_weight</span>
            <span class="k">return</span> <span class="n">weight</span>

    <span class="s2">&#34;&#34;&#34;2. Noisy linear module for the last two layers of A and V function &#34;&#34;&#34;</span>
    <span class="k">class</span> <span class="nc">NoisyLinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">std_init</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">mu_range</span><span class="p">,</span> <span class="n">mu_range</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">std_init</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_features</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_epsilon</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_mu</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_sigma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_epsilon</span><span class="p">)</span>
    
    <span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">atom_size</span><span class="p">,</span> <span class="n">support</span><span class="p">):</span>
            <span class="s2">&#34;&#34;&#34;
</span><span class="s2">                atom size: N actions in M (atom_size) value support
</span><span class="s2">                support: torch.linspace(v_min, v_max, atom_size)
</span><span class="s2">            &#34;&#34;&#34;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">feature_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">advantage_hidden_layer</span> <span class="o">=</span> <span class="n">NoisyLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">advantage_layer</span> <span class="o">=</span> <span class="n">NoisyLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_dim</span> <span class="o">*</span> <span class="n">atom_size</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_hidden_layer</span> <span class="o">=</span> <span class="n">NoisyLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">value_layer</span> <span class="o">=</span> <span class="n">NoisyLinear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">atom_size</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="s2">&#34;&#34;&#34;Get distribution for atoms.&#34;&#34;&#34;</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">adv_hid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">advantage_hidden_layer</span><span class="p">(</span><span class="n">feature</span><span class="p">))</span>
            <span class="n">val_hid</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_hidden_layer</span><span class="p">(</span><span class="n">feature</span><span class="p">))</span>
            <span class="n">advantage</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">advantage_layer</span><span class="p">(</span><span class="n">adv_hid</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_size</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_layer</span><span class="p">(</span><span class="n">val_hid</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_size</span><span class="p">)</span>
            <span class="n">q_atoms</span> <span class="o">=</span> <span class="n">value</span> <span class="o">+</span> <span class="n">advantage</span> <span class="o">-</span> <span class="n">advantage</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">q_atoms</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>  <span class="o">//</span> <span class="k">for</span> <span class="n">avoiding</span> <span class="n">nans</span>
            <span class="k">return</span> <span class="n">dist</span>

        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dist</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">q</span>

     <span class="s2">&#34;&#34;&#34;3. When you put them together &#34;&#34;&#34;</span>
     <span class="k">class</span> <span class="nc">Agent</span><span class="p">:</span>
        <span class="s2">&#34;&#34;&#34;Attribute:
</span><span class="s2">            1. env (gym.Env): openAI Gym environment
</span><span class="s2">            2. memory (PrioritizedReplayBuffer): replay memory to store transitions
</span><span class="s2">                - alpha (float): determines how much prioritization is used
</span><span class="s2">                - beta (float): determines how much importance sampling is used
</span><span class="s2">                - prior_eps (float): guarantees every transition can be sampled
</span><span class="s2">            3. batch_size (int): batch size for sampling
</span><span class="s2">            4. target_update (int): period for target model&#39;s hard update
</span><span class="s2">            5. gamma (float): discount factor
</span><span class="s2">            6. Categorical+Double+Dueling+NoisyLinear Network
</span><span class="s2">                - v_min (float): min value of support
</span><span class="s2">                - v_max (float): max value of support
</span><span class="s2">                - atom_size (int): the unit number of support
</span><span class="s2">                - support (torch.Tensor): support for categorical dqn
</span><span class="s2">            7. n_step (int): step number to calculate n-step td error
</span><span class="s2">        &#34;&#34;&#34;</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dqn</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span><span class="n">obs_dim</span><span class="p">,</span> <span class="n">action_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dqn_target</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dqn_target</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transition</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>        <span class="o">//</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">act</span><span class="p">,</span> <span class="n">rew</span><span class="p">,</span> <span class="n">next_obs</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">is_test</span> <span class="o">=</span> <span class="bp">False</span>            <span class="o">//</span><span class="n">mode</span><span class="p">:</span> <span class="n">train</span><span class="o">/</span><span class="n">test</span>

        <span class="k">def</span> <span class="nf">select_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_test</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">transition</span> <span class="o">=</span> <span class="p">[</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">action</span>

        <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
            <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_test</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">transition</span> <span class="o">+=</span> <span class="p">[</span><span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">transition</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span>

        <span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">sample_batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&#34;weights&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">samples</span><span class="p">[</span><span class="s2">&#34;indices&#34;</span><span class="p">]</span>
            <span class="o">//</span> <span class="mf">1.</span> <span class="n">combine</span> <span class="mi">1</span><span class="o">-</span><span class="n">step</span> <span class="ow">and</span> <span class="n">n</span><span class="o">-</span><span class="n">step</span> <span class="n">loss</span> <span class="n">to</span> <span class="n">prevent</span> <span class="n">high</span><span class="o">-</span><span class="n">variance</span>
            <span class="n">loss_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_dqn_loss</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>
            <span class="n">gamma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_step</span>
            <span class="n">loss_</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_dqn_loss</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">gamma</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span>
            <span class="o">//</span> <span class="mf">2.</span> <span class="n">update</span> <span class="n">network</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">clip_grad_norm_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">10.0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="o">//</span> <span class="mf">3.</span> <span class="n">update</span> <span class="n">sample</span> <span class="n">priorities</span>
            <span class="n">loss_for_prior</span> <span class="o">=</span> <span class="n">loss_</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">new_priorities</span> <span class="o">=</span> <span class="n">loss_for_prior</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_eps</span> <span class="o">//</span><span class="n">to</span> <span class="n">prevent</span> <span class="n">zero</span> <span class="n">prior_eps</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">update_priorities</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">new_priorities</span><span class="p">)</span>
            <span class="o">//</span> <span class="mf">4.</span> <span class="n">reset</span> <span class="n">noisynet</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="o">.</span><span class="n">reset_noise</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dqn_target</span><span class="o">.</span><span class="n">reset_noise</span><span class="p">()</span>
        
        <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_frames</span><span class="p">,</span> <span class="n">plot_interval</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_test</span> <span class="o">=</span> <span class="bp">False</span>   
            <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
            <span class="n">update_cnt</span> <span class="o">=</span> <span class="mi">0</span> 
            <span class="n">losses</span><span class="p">,</span> <span class="n">scores</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">frame_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_frames</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">select_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
                <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>
                <span class="n">score</span> <span class="o">+=</span> <span class="n">reward</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">+</span> <span class="nb">min</span><span class="p">(</span><span class="n">frame_idx</span><span class="o">/</span><span class="n">num_frames</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                    <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
                    <span class="n">score</span> <span class="o">=</span> <span class="mi">0</span> 
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">memory</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">()</span>
                    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                    <span class="n">update_cnt</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">update_cnt</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_update</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">dqn_target</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">frame_idx</span> <span class="o">%</span> <span class="n">plot_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_plot</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame_idx</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
            <span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
            <span class="n">clear_output</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;frame </span><span class="si">%s</span><span class="s2">. score: </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span><span class="p">(</span><span class="n">frame_idx</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:])))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_compute_dqn_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
            <span class="s2">&#34;&#34;&#34;calculate categorical dqn loss&#34;&#34;&#34;</span>
            <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&#34;obs&#34;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">next_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&#34;next_obs&#34;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&#34;acts&#34;</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">reward</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&#34;rews&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="s2">&#34;done&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">delta_z</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">v_max</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">atom_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="o">//</span> <span class="mf">1.</span> <span class="n">choose</span> <span class="n">best</span> <span class="nb">next</span> <span class="n">action</span> <span class="o">=</span> <span class="n">argmax</span> <span class="n">Q</span><span class="p">(</span><span class="n">s_</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
                <span class="n">next_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">next_dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dqn_target</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">next_state</span><span class="p">)</span>
                <span class="n">next_dist</span> <span class="o">=</span> <span class="n">next_dist</span><span class="p">[</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">next_action</span><span class="p">]</span>
                <span class="o">//</span> <span class="mf">2.</span> <span class="n">compute</span> <span class="n">projection</span> <span class="n">of</span> <span class="n">t_z</span> <span class="n">onto</span> <span class="n">the</span> <span class="n">support</span> <span class="n">z</span>
                <span class="n">t_z</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">done</span><span class="p">)</span> <span class="o">*</span> <span class="n">gamma</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">support</span>
                <span class="n">t_z</span> <span class="o">=</span> <span class="n">t_z</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v_min</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v_max</span><span class="p">)</span>
                <span class="n">b</span> <span class="o">=</span> <span class="p">(</span><span class="n">t_z</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">v_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">delta_z</span>
                <span class="n">l</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">floor</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">ceil</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="o">//</span> <span class="mf">3.</span> <span class="n">get</span> <span class="n">distribution</span> <span class="n">of</span> <span class="n">Q</span> <span class="n">value</span> <span class="n">on</span> <span class="n">the</span> <span class="n">support</span>
                <span class="n">offset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_size</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">atom_size</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">proj_dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">next_dist</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">proj_dist</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),(</span><span class="n">next_dist</span> <span class="o">*</span> <span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">proj_dist</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">u</span> <span class="o">+</span> <span class="n">offset</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),(</span><span class="n">next_dist</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">l</span><span class="o">.</span><span class="n">float</span><span class="p">()))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="o">//</span> <span class="mf">4.</span> <span class="n">calculate</span> <span class="n">cross</span> <span class="n">entropy</span> <span class="n">loss</span>
            <span class="n">log_p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dqn</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">state</span><span class="p">)[</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">action</span><span class="p">])</span>
            <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">proj_dist</span> <span class="o">*</span> <span class="n">log_p</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>loss计算过程</strong>:</p>
<ol>
<li>根据$s_{t+n}$计算相对应的$Q(s_{t+n},a ; \theta) = \sum_i  z_i \Pr_i(s_{t+n},a; \theta)$ (见<code>network forward()</code>)</li>
<li>$a^* \gets \arg\max_a Q(s_{t+n},a ; \theta)$ 得到 <code>next_action</code></li>
<li>通过<code>dqn_target</code> 得到 $\Pr(s_{t+n}, a ; \theta&rsquo;)$，然后根据<code>next_dist[range(self.batch_size), a*]</code>得到<code>double Q probabilities</code>用于计算<code>cross entropy</code></li>
<li>对每一个<code>Q support</code>，计算对应的<code>projection</code> $b_i = ([r_{t+n} + \gamma^n z_i] - V_\min) / \Delta z$</li>
<li>计算<code>projection</code> $\mathbb{b}$ 的上界和下界 $u$ and $l$</li>
<li>将每一个<code>batch</code>的结果加到<code>distribution</code>里
$$\begin{align*}
m_l &amp;\gets m_l + \Pr(s_{t+n}, a^* ; \theta&rsquo;)\times(u-b) \cr
m_u &amp;\gets m_u + \Pr(s_{t+n}, a^* ; \theta&rsquo;)\times(b-l)
\end{align*}$$</li>
<li>目标是尽量缩小<code>target Q dist</code>(即上面的$m$) 和 <code>eval Q dist</code>(即上面的<code>dqn.dist(state, action)</code>) 之间的<code>KL distance</code>，所以用<code>cross-entropy loss</code> 即希望<code>sample(s,a,r,s')</code>中(s,a)估计的<code>predicted Q值分布</code>和(r,s&rsquo;)估计的<code>target Q值分布</code>差异不大</li>
</ol>

  </div>
</div>
</p>
</li>
</ul>
<h2 id="policy-gradient">Policy Gradient</h2>
<!-- a list of [papers](https://spinningup.openai.com/en/latest/spinningup/keypapers.html) in deep RL that are worth reading -->
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Double DQN为啥不用最优策略预测目标值: 通过一个比较好的策略在某个状态下的平均回报来估计<code>true Q value</code>，这个<code>target Q value</code>被高估是因为在<code>value iteration</code>中 $$\forall s,a \quad Q^*(s,a) = \sum_{s&rsquo;}P_{sa}^{s&rsquo;}(R_{sa}^{s&rsquo;}+\gamma \max_a Q^*(s&rsquo;,a)) \leq R_{sa}^{s&rsquo;}+\gamma \max_a Q^*(s&rsquo;,a)$$ <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>分布学习: 学习价值的概率分布显然要比只学习它的期望更加靠谱，比如一个<code>env</code>中<code>V(s,a)</code>的真实分布是一个关于<code>action</code>的双峰分布，那么只是通过预测一个期望回报显然不能很好的评估当前状态的价值，训练过程中容易陷入局部最优，最后得到一个关于<code>action</code>的单峰分布, 详细请看<a href="https://zhang-yi-chi.github.io/2018/09/19/DistributionalRL/">这里</a>
<img src="pics/cdqn.png" alt="ff" class="center" width="30%"> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
	

<a href="#" id="back-to-top" class="back-to-top" style="display: inline;">Back to Top</a>

<script>
  var link = document.getElementById("back-to-top");
  var amountScrolled = 1000;

  window.addEventListener('scroll', function(e) {
      if ( window.pageYOffset > amountScrolled ) {
          link.classList.add('show');
      } else {
          link.className = 'back-to-top';
      }
  });

<!-- Scrolls to Top -->
  link.addEventListener('click', function(e) {
      e.preventDefault();

      var distance = 0 - window.pageYOffset;
      var increments = distance/(500/16);
      function animateScroll() {
          window.scrollBy(0, increments);
          if (window.pageYOffset <= document.body.offsetTop) {
              clearInterval(runAnimation);
          }
      };
      
      var runAnimation = setInterval(animateScroll, 16);
  });
</script>

<style>
  .back-to-top {
    background: #111;
    color: #fefefe;
    opacity: 0;
    transition: opacity .6s ease-in-out;
    z-index: 999;
    position: fixed;
    right: 30px;
    bottom: 30px;
    width: auto;
    height: auto;
    box-sizing: border-box;
    border-radius: 0.4em;
    word-wrap: normal !important;
  }

  a.back-to-top {
    font-weight: bold;
    letter-spacing: 0px;
    font-size: 0.75rem;
    font-family: inherit;
    text-transform: uppercase;
    text-align: center;
    padding: 0.65em 0.55em;
  }

  .back-to-top:hover, .back-to-top:focus, .back-to-top:visited {
    color: #fefefe;
    border-bottom: none;
  }

  .back-to-top.show {
    opacity: 1;
  }
</style>


  </main>
  <div id="disqus-container">
  
</div>


          <footer role="contentinfo">
  <div>
    <label for="themer">
      dark theme: <input type="checkbox" id="themer" class="vh">
      <span aria-hidden="true"></span>
    </label>
  </div>
  
    © 2020
  
</footer>

        </div>
      </div>
    </div>
    <script src="https://dennislblog.github.io/cnblog/js/prism.js"></script>
<script src="https://dennislblog.github.io/cnblog/js/dom-scripts.js"></script>
<script src='https://kit.fontawesome.com/a076d05399.js'></script>
    
  

  </body>
</html>
