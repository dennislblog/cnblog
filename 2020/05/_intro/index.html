<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="generator" content="Hugo 0.69.0" />
  <link rel="canonical" href="https://dennislblog.github.io/2020/05/_intro/">

  

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#000000">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" href="https://dennislblog.github.io/css/prism.css" media="none" onload="this.media='all';">

  
  
  <link rel="stylesheet" type="text/css" href="https://dennislblog.github.io/css/styles.css">

  <style id="inverter" media="none">
    .intro-and-nav, .main-and-footer { filter: invert(100%) }
    * { background-color: inherit }
    img:not([src*=".svg"]), .colors, iframe, .demo-container { filter: invert(100%) }
  </style>

  
  
  <title>基本入门 | My Site Title</title>
  

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"]},
    },
    "HTML-CSS": {
    	scale: 80,
    	styles: {
    		".MathJax": {color: "rgb(91, 58, 17)",}
    	},
    },
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>




</head>

  <body>
    <a href="#main">skip to content</a>
    <svg style="display: none">
  <symbol id="bookmark" viewBox="0 0 40 50">
   <g transform="translate(2266 3206.2)">
    <path style="stroke:currentColor;stroke-width:3.2637;fill:none" d="m-2262.2-3203.4-.2331 42.195 16.319-16.318 16.318 16.318.2331-42.428z"/>
   </g>
  </symbol>

  <symbol id="w3c" viewBox="0 0 127.09899 67.763">
   <text font-size="83" style="font-size:83px;font-family:Trebuchet;letter-spacing:-12;fill-opacity:0" letter-spacing="-12" y="67.609352" x="-26.782778">W3C</text>
   <text font-size="83" style="font-size:83px;font-weight:bold;font-family:Trebuchet;fill-opacity:0" y="67.609352" x="153.21722" font-weight="bold">SVG</text>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m33.695.377 12.062 41.016 12.067-41.016h8.731l-19.968 67.386h-.831l-12.48-41.759-12.479 41.759h-.832l-19.965-67.386h8.736l12.061 41.016 8.154-27.618-3.993-13.397h8.737z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m91.355 46.132c0 6.104-1.624 11.234-4.862 15.394-3.248 4.158-7.45 6.237-12.607 6.237-3.882 0-7.263-1.238-10.148-3.702-2.885-2.47-5.02-5.812-6.406-10.022l6.82-2.829c1.001 2.552 2.317 4.562 3.953 6.028 1.636 1.469 3.56 2.207 5.781 2.207 2.329 0 4.3-1.306 5.909-3.911 1.609-2.606 2.411-5.738 2.411-9.401 0-4.049-.861-7.179-2.582-9.399-1.995-2.604-5.129-3.912-9.397-3.912h-3.327v-3.991l11.646-20.133h-14.062l-3.911 6.655h-2.493v-14.976h32.441v4.075l-12.31 21.217c4.324 1.385 7.596 3.911 9.815 7.571 2.22 3.659 3.329 7.953 3.329 12.892z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.21 0 1.414 8.6-5.008 9.583s-1.924-4.064-5.117-6.314c-2.693-1.899-4.447-2.309-7.186-1.746-3.527.73-7.516 4.938-9.258 10.13-2.084 6.21-2.104 9.218-2.178 11.978-.115 4.428.58 7.043.58 7.043s-3.04-5.626-3.011-13.866c.018-5.882.947-11.218 3.666-16.479 2.404-4.627 5.954-7.404 9.114-7.728 3.264-.343 5.848 1.229 7.841 2.938 2.089 1.788 4.213 5.698 4.213 5.698l4.94-9.837z"/>
   <path style="fill:currentColor;image-rendering:optimizeQuality;shape-rendering:geometricPrecision" d="m125.82 48.674s-2.208 3.957-3.589 5.48c-1.379 1.524-3.849 4.209-6.896 5.555-3.049 1.343-4.646 1.598-7.661 1.306-3.01-.29-5.807-2.032-6.786-2.764-.979-.722-3.486-2.864-4.897-4.854-1.42-2-3.634-5.995-3.634-5.995s1.233 4.001 2.007 5.699c.442.977 1.81 3.965 3.749 6.572 1.805 2.425 5.315 6.604 10.652 7.545 5.336.945 9.002-1.449 9.907-2.031.907-.578 2.819-2.178 4.032-3.475 1.264-1.351 2.459-3.079 3.116-4.108.487-.758 1.276-2.286 1.276-2.286l-1.276-6.644z"/>
  </symbol>

  <symbol id="tag" viewBox="0 0 177.16535 177.16535">
    <g transform="translate(0 -875.2)">
     <path style="fill-rule:evenodd;stroke-width:0;fill:currentColor" d="m159.9 894.3-68.79 8.5872-75.42 77.336 61.931 60.397 75.429-76.565 6.8495-69.755zm-31.412 31.835a10.813 10.813 0 0 1 1.8443 2.247 10.813 10.813 0 0 1 -3.5174 14.872l-.0445.0275a10.813 10.813 0 0 1 -14.86 -3.5714 10.813 10.813 0 0 1 3.5563 -14.863 10.813 10.813 0 0 1 13.022 1.2884z"/>
    </g>
  </symbol>

  <symbol id="balloon" viewBox="0 0 141.73228 177.16535">
   <g transform="translate(0 -875.2)">
    <g>
     <path style="fill:currentColor" d="m68.156 882.83-.88753 1.4269c-4.9564 7.9666-6.3764 17.321-5.6731 37.378.36584 10.437 1.1246 23.51 1.6874 29.062.38895 3.8372 3.8278 32.454 4.6105 38.459 4.6694-.24176 9.2946.2879 14.377 1.481 1.2359-3.2937 5.2496-13.088 8.886-21.623 6.249-14.668 8.4128-21.264 10.253-31.252 1.2464-6.7626 1.6341-12.156 1.4204-19.764-.36325-12.93-2.1234-19.487-6.9377-25.843-2.0833-2.7507-6.9865-7.6112-7.9127-7.8436-.79716-.20019-6.6946-1.0922-6.7755-1.0248-.02213.0182-5.0006-.41858-7.5248-.22808l-2.149-.22808h-3.3738z"/>
     <path style="fill:currentColor" d="m61.915 883.28-3.2484.4497c-1.7863.24724-3.5182.53481-3.8494.63994-2.4751.33811-4.7267.86957-6.7777 1.5696-.28598 0-1.0254.20146-2.3695.58589-5.0418 1.4418-6.6374 2.2604-8.2567 4.2364-6.281 7.6657-11.457 18.43-12.932 26.891-1.4667 8.4111.71353 22.583 5.0764 32.996 3.8064 9.0852 13.569 25.149 22.801 37.517 1.3741 1.841 2.1708 2.9286 2.4712 3.5792 3.5437-1.1699 6.8496-1.9336 10.082-2.3263-1.3569-5.7831-4.6968-21.86-6.8361-33.002-.92884-4.8368-2.4692-14.322-3.2452-19.991-.68557-5.0083-.77707-6.9534-.74159-15.791.04316-10.803.41822-16.162 1.5026-21.503 1.4593-5.9026 3.3494-11.077 6.3247-15.852z"/>
     <path style="fill:currentColor" d="m94.499 885.78c-.10214-.0109-.13691 0-.0907.0409.16033.13489 1.329 1.0675 2.5976 2.0723 6.7003 5.307 11.273 14.568 12.658 25.638.52519 4.1949.24765 14.361-.5059 18.523-2.4775 13.684-9.7807 32.345-20.944 53.519l-3.0559 5.7971c2.8082.76579 5.7915 1.727 8.9926 2.8441 11.562-11.691 18.349-19.678 24.129-28.394 7.8992-11.913 11.132-20.234 12.24-31.518.98442-10.02-1.5579-20.876-6.7799-28.959-.2758-.4269-.57803-.86856-.89617-1.3166-3.247-6.13-9.752-12.053-21.264-16.131-2.3687-.86369-6.3657-2.0433-7.0802-2.1166z"/>
     <path style="fill:currentColor" d="m32.52 892.22c-.20090-.13016-1.4606.81389-3.9132 2.7457-11.486 9.0476-17.632 24.186-16.078 39.61.79699 7.9138 2.4066 13.505 5.9184 20.562 5.8577 11.77 14.749 23.219 30.087 38.74.05838.059.12188.1244.18052.1838 1.3166-.5556 2.5965-1.0618 3.8429-1.5199-.66408-.32448-1.4608-1.3297-3.8116-4.4602-5.0951-6.785-8.7512-11.962-13.051-18.486-5.1379-7.7948-5.0097-7.5894-8.0586-13.054-6.2097-11.13-8.2674-17.725-8.6014-27.563-.21552-6.3494.13041-9.2733 1.775-14.987 2.1832-7.5849 3.9273-10.986 9.2693-18.07 1.7839-2.3656 2.6418-3.57 2.4409-3.7003z"/>
     <path style="fill:currentColor" d="m69.133 992.37c-6.2405.0309-12.635.76718-19.554 2.5706 4.6956 4.7759 9.935 10.258 12.05 12.625l4.1272 4.6202h11.493l3.964-4.4516c2.0962-2.3541 7.4804-7.9845 12.201-12.768-8.378-1.4975-16.207-2.6353-24.281-2.5955z"/>
     <rect style="stroke-width:0;fill:currentColor" ry="2.0328" height="27.746" width="22.766" y="1017.7" x="60.201"/>
    </g>
   </g>
  </symbol>

  <symbol id="info" viewBox="0 0 41.667 41.667">
   <g transform="translate(-37.035 -1004.6)">
    <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m76.25 1030.2a18.968 18.968 0 0 1 -23.037 13.709 18.968 18.968 0 0 1 -13.738 -23.019 18.968 18.968 0 0 1 23.001 -13.768 18.968 18.968 0 0 1 13.798 22.984"/>
    <g transform="matrix(1.1146 0 0 1.1146 -26.276 -124.92)">
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:3.728;fill:none" d="m75.491 1039.5v-8.7472"/>
     <path style="stroke-width:0;fill:currentColor" transform="scale(-1)" d="m-73.193-1024.5a2.3719 2.3719 0 0 1 -2.8807 1.7142 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
   </g>
  </symbol>

  <symbol id="warning" viewBox="0 0 48.430474 41.646302">
    <g transform="translate(-1.1273 -1010.2)">
     <path style="stroke-linejoin:round;stroke:currentColor;stroke-linecap:round;stroke-width:4.151;fill:none" d="m25.343 1012.3-22.14 37.496h44.28z"/>
     <path style="stroke:currentColor;stroke-linecap:round;stroke-width:4.1512;fill:none" d="m25.54 1027.7v8.7472"/>
     <path style="stroke-width:0;fill:currentColor" d="m27.839 1042.8a2.3719 2.3719 0 0 1 -2.8807 1.7143 2.3719 2.3719 0 0 1 -1.718 -2.8785 2.3719 2.3719 0 0 1 2.8763 -1.7217 2.3719 2.3719 0 0 1 1.7254 2.8741"/>
    </g>
  </symbol>

  <symbol id="menu" viewBox="0 0 50 50">
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="0" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="20" x="0"/>
     <rect style="stroke-width:0;fill:currentColor" height="10" width="50" y="40" x="0"/>
   </symbol>

   <symbol id="link" viewBox="0 0 50 50">
    <g transform="translate(0 -1002.4)">
     <g transform="matrix(.095670 0 0 .095670 2.3233 1004.9)">
      <g>
       <path style="stroke-width:0;fill:currentColor" d="m452.84 192.9-128.65 128.65c-35.535 35.54-93.108 35.54-128.65 0l-42.881-42.886 42.881-42.876 42.884 42.876c11.845 11.822 31.064 11.846 42.886 0l128.64-128.64c11.816-11.831 11.816-31.066 0-42.9l-42.881-42.881c-11.822-11.814-31.064-11.814-42.887 0l-45.928 45.936c-21.292-12.531-45.491-17.905-69.449-16.291l72.501-72.526c35.535-35.521 93.136-35.521 128.64 0l42.886 42.881c35.535 35.523 35.535 93.141-.001 128.66zm-254.28 168.51-45.903 45.9c-11.845 11.846-31.064 11.817-42.881 0l-42.884-42.881c-11.845-11.821-11.845-31.041 0-42.886l128.65-128.65c11.819-11.814 31.069-11.814 42.884 0l42.886 42.886 42.876-42.886-42.876-42.881c-35.54-35.521-93.113-35.521-128.65 0l-128.65 128.64c-35.538 35.545-35.538 93.146 0 128.65l42.883 42.882c35.51 35.54 93.11 35.54 128.65 0l72.496-72.499c-23.956 1.597-48.092-3.784-69.474-16.283z"/>
      </g>
     </g>
    </g>
  </symbol>

  <symbol id="doc" viewBox="0 0 35 45">
   <g transform="translate(-147.53 -539.83)">
    <path style="stroke:currentColor;stroke-width:2.4501;fill:none" d="m149.38 542.67v39.194h31.354v-39.194z"/>
    <g style="stroke-width:25" transform="matrix(.098003 0 0 .098003 133.69 525.96)">
     <path d="m220 252.36h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path style="stroke:currentColor;stroke-width:25;fill:none" d="m220 409.95h200"/>
     <path d="m220 488.74h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
     <path d="m220 331.15h200" style="stroke:currentColor;stroke-width:25;fill:none"/>
    </g>
   </g>
 </symbol>

 <symbol id="tick" viewBox="0 0 177.16535 177.16535">
  <g transform="translate(0 -875.2)">
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="155" width="40" y="702.99" x="556.82"/>
   <rect style="stroke-width:0;fill:currentColor" transform="rotate(30)" height="40" width="90.404" y="817.99" x="506.42"/>
  </g>
 </symbol>
</svg>

    <div class="wrapper">
      <header class="intro-and-nav" role="banner">
  <div>
    <div class="intro">
      <a class="logo" href="/" aria-label="My Site Title home page">
        <img src="https://dennislblog.github.io/pics/logo.svg" alt="">
      </a>
      <p class="library-desc">
        
        Hello, you all
        
      </p>
    </div>
    <nav id="patterns-nav" class="patterns" role="navigation">
  <h2 class="vh">Main navigation</h2>
  <button id="menu-button" aria-expanded="false">
    <svg viewBox="0 0 50 50" aria-hidden="true" focusable="false">
      <use xlink:href="#menu"></use>
    </svg>
    Menu
  </button>
  
  <ul id="patterns-list">
  
    <li class="pattern">
      
      
      
      
      <a href="/post/" aria-current="page">
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use xlink:href="#bookmark"></use>
        </svg>
        <span class="text">Blog</span>
      </a>
    </li>
  
    <li class="pattern">
      
      
      
      
      <a href="/tags/" >
        <svg class="bookmark-icon" aria-hidden="true" focusable="false" viewBox="0 0 40 50">
          <use xlink:href="#bookmark"></use>
        </svg>
        <span class="text">Tags</span>
      </a>
    </li>
  
  </ul>
</nav>
    
    



  <hr>
  <nav class="patterns" aria-labelledby="toc-heading">
    <h4 id="toc-heading" style="margin-bottom: 1em">Table of contents</h4> 
    <ol>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#%e5%9f%ba%e7%a1%80%e9%85%8d%e7%bd%ae" style="padding-left: 0rem">
            基础配置
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#cudagpu%e8%bf%90%e7%ae%97" style="padding-left: 0rem">
            CUDA/GPU运算
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#%e5%9b%ba%e5%ae%9a%e9%9a%8f%e6%9c%ba%e7%a7%8d%e5%ad%90" style="padding-left: 0rem">
            固定随机种子
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#%e6%b8%85%e9%99%a4gpu%e5%ad%98%e5%82%a8" style="padding-left: 0rem">
            清除GPU存储
          </a>
        </li>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#tensor-%e8%bf%90%e7%ae%97" style="padding-left: 0rem">
            Tensor 运算
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#%e5%9f%ba%e6%9c%ac%e4%bf%a1%e6%81%af" style="padding-left: 0rem">
            基本信息
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#%e6%95%b0%e6%8d%ae%e7%b1%bb%e5%9e%8b%e8%bd%ac%e6%8d%a2" style="padding-left: 0rem">
            数据类型转换
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#%e5%88%9b%e5%bb%ba-tensor" style="padding-left: 0rem">
            创建 Tensor
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#tensor-%e6%93%8d%e4%bd%9c" style="padding-left: 0rem">
            Tensor 操作
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#autograd%e5%ba%93" style="padding-left: 0rem">
            autograd库
          </a>
        </li>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80" style="padding-left: 0rem">
            深度学习基础
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92" style="padding-left: 0rem">
            线性回归
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#softmax%e5%9b%9e%e5%bd%92" style="padding-left: 0rem">
            Softmax回归
          </a>
        </li>
      
        
        <li class="toc-h2">
          
          
          
          
          <a href="#%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e8%bf%9b%e9%98%b6" style="padding-left: 0rem">
            深度学习进阶
          </a>
        </li>
      
        
        <li class="toc-h3">
          
          
          
          
          <a href="#variable-detach-%e4%b8%8e-detach_" style="padding-left: 0rem">
            Variable detach 与 detach_
          </a>
        </li>
      
    </ol>
  </nav>





    
  </div>
</header>
      <div class="main-and-footer">
        <div>
          
  <main id="main">
    <h1>
      <svg class="bookmark-icon" aria-hidden="true" viewBox="0 0 40 50" focusable="false">
        <use xlink:href="#bookmark"></use>
      </svg>
      基本入门
    </h1>

    <div class="date">
      
      
      <strong aria-hidden="true">Publish date: </strong>Wednesday, May 20, 2020
      
        
      
    </div>

    
      <div class="tags">
        <strong aria-hidden="true">Tags: </strong>
        <ul aria-label="tags">
          
            <li>
              <svg class="tag-icon" aria-hidden="true" viewBox="0 0 177.16535 177.16535" focusable="false">
                <use xlink:href="#tag"></use>
              </svg>
              
              <a href="https://dennislblog.github.io/tags/pytorch/">PyTorch</a>
            </li>
          
        </ul>
      </div>
    
    <h2 id="基础配置">基础配置</h2>
<h3 id="cudagpu运算">CUDA/GPU运算</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    torch<span style="color:#666">.</span>cuda<span style="color:#666">.</span>get_device_name(<span style="color:#40a070">0</span>)   <span style="color:#666">//</span><span style="color:#4070a0">&#39;GeForce GTX 1060&#39;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    torch<span style="color:#666">.</span>cuda<span style="color:#666">.</span>is_available()       <span style="color:#666">//</span><span style="">判断</span> GPU <span style="">支持</span>
</code></pre></div><h3 id="固定随机种子">固定随机种子</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    torch<span style="color:#666">.</span>manual_seed(<span style="color:#40a070">0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    torch<span style="color:#666">.</span>cuda<span style="color:#666">.</span>manual_seed_all(<span style="color:#40a070">0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    torch<span style="color:#666">.</span>backends<span style="color:#666">.</span>cudnn<span style="color:#666">.</span>deterministic <span style="color:#666">=</span> True   <span style="color:#666">//</span><span style="">去除随机性？</span>
</code></pre></div><h3 id="清除gpu存储">清除GPU存储</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    torch<span style="color:#666">.</span>cuda<span style="color:#666">.</span>empty_cache()        <span style="color:#666">//</span><span style="">有时</span>Ctrl <span style="color:#666">+</span> C中止程序<span style="">，</span>GPU存储没有释放
</code></pre></div><h2 id="tensor-运算">Tensor 运算</h2>
<h3 id="基本信息">基本信息</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    tensor<span style="color:#666">.</span>type()   <span style="color:#666">//</span><span style="">数据类型，例如</span> <span style="color:#4070a0">`torch.FloatTensor`</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    tensor<span style="color:#666">.</span>size()   <span style="color:#666">//</span><span style="">数据形状，例如</span> <span style="color:#4070a0">`torch.Size([4, 2])`</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    tensor<span style="color:#666">.</span>dim()    <span style="color:#666">//</span><span style="">数据维度，例如</span> <span style="color:#4070a0">`2`</span>
</code></pre></div><h3 id="数据类型转换">数据类型转换</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    tensor <span style="color:#666">=</span> tensor<span style="color:#666">.</span>cuda()           <span style="color:#666">//</span>tensor(data, device<span style="color:#666">=</span><span style="color:#4070a0">&#39;cuda:0&#39;</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    tensor <span style="color:#666">=</span> tensor<span style="color:#666">.</span>cpu()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    tensor <span style="color:#666">=</span> tensor<span style="color:#666">.</span>float()          <span style="color:#666">//</span>Float类型比Double要快很多
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span>    b <span style="color:#666">=</span> a<span style="color:#666">.</span>cpu()<span style="color:#666">.</span>numpy()              <span style="color:#666">//</span>torch<span style="color:#666">.</span>Tensor (cpu) <span style="color:#666">--&gt;</span> np<span style="color:#666">.</span>ndarray 
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span>    b <span style="color:#666">=</span> torch<span style="color:#666">.</span>from_numpy(a<span style="color:#666">.</span>copy())   <span style="color:#666">//</span><span style="">如果不加</span>copy()<span style="">则共享内存</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6</span>    b <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(a)              <span style="color:#666">//</span><span style="">数据拷贝，不共享内存</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7</span>    b <span style="color:#666">=</span> a<span style="color:#666">.</span>numpy(); a<span style="color:#666">.</span>add_(<span style="color:#40a070">1</span>)         <span style="color:#666">//</span>b也会数据加1, <span style="">同理</span>torch<span style="color:#666">.</span>from_numpy(a)<span style="">也是共享内存</span>
</code></pre></div><h3 id="创建-tensor">创建 Tensor</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    empty <span style="color:#666">=</span> torch<span style="color:#666">.</span>empty(<span style="color:#40a070">2</span>, <span style="color:#40a070">3</span>)  <span style="color:#666">//</span><span style="">每一次</span>call <span style="color:#007020;font-weight:bold">print</span>(empty)<span style="">结果都不一样，因为数据还未指定</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    empty_like <span style="color:#666">=</span> torch<span style="color:#666">.</span>empty_like(empty)               <span style="color:#666">//</span><span style="">返回</span>size一模一样的未定义张量
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    eye <span style="color:#666">=</span> torch<span style="color:#666">.</span>eye(<span style="color:#40a070">3</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span>    zeros <span style="color:#666">=</span> torch<span style="color:#666">.</span>zeros(<span style="color:#40a070">3</span>, <span style="color:#40a070">2</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span>    ones <span style="color:#666">=</span> torch<span style="color:#666">.</span>ones(<span style="color:#40a070">2</span>, <span style="color:#40a070">3</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6</span>    rand <span style="color:#666">=</span> torch<span style="color:#666">.</span>rand(<span style="color:#40a070">2</span>, <span style="color:#40a070">3</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7</span>    randn <span style="color:#666">=</span> torch<span style="color:#666">.</span>randn(<span style="color:#40a070">2</span>, <span style="color:#40a070">3</span>)                          <span style="color:#666">//</span><span style="">返回一个</span>normal(<span style="color:#40a070">0</span>,<span style="color:#40a070">1</span>)<span style="">的张量</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">8</span>    randint <span style="color:#666">=</span> torch<span style="color:#666">.</span>randint(low<span style="color:#666">=</span><span style="color:#40a070">3</span>,high<span style="color:#666">=</span><span style="color:#40a070">5</span>,size<span style="color:#666">=</span>(<span style="color:#40a070">3</span>,)) 
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">9</span>    tensor <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor([<span style="color:#40a070">2</span>,<span style="color:#40a070">8</span>])                       <span style="color:#666">//</span><span style="">不共享内存</span>
</code></pre></div><h3 id="tensor-操作">Tensor 操作</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>y <span style="color:#666">=</span> x[<span style="color:#40a070">0</span>, :]; y <span style="color:#666">+=</span> <span style="color:#40a070">1</span>                            <span style="color:#666">//</span><span style="">索引共享内存</span>, x[<span style="color:#40a070">0</span>]<span style="">也变了</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    z <span style="color:#666">=</span> x<span style="color:#666">.</span>view(<span style="color:#666">-</span><span style="color:#40a070">1</span>, <span style="color:#40a070">5</span>)                          <span style="color:#666">//</span>view()<span style="">改变形状</span>, <span style="">同样共享内存</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>z_cp <span style="color:#666">=</span> x<span style="color:#666">.</span>clone()<span style="color:#666">.</span>view(<span style="color:#666">-</span><span style="color:#40a070">1</span>, <span style="color:#40a070">5</span>)                   <span style="color:#666">//</span><span style="">不想共享内存就先</span>clone()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span><span style="color:#007020;font-weight:bold">print</span>(x[<span style="color:#40a070">0</span>][<span style="color:#40a070">0</span>]<span style="color:#666">.</span>item())                          <span style="color:#666">//</span><span style="">将一个标量</span>Tensor转换成一个Python number
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span>y[:] <span style="color:#666">=</span> y <span style="color:#666">+</span> x; y<span style="color:#666">.</span>add_(x)                        <span style="color:#666">//</span><span style="color:#007020">id</span>(y_before) <span style="color:#666">=</span> <span style="color:#007020">id</span>(y) <span style="">不重新分配内存</span>
</code></pre></div><h3 id="autograd库">autograd库</h3>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span>    <span style="color:#666">//</span><span style="">必须是</span><span style="color:#4070a0">`Float`</span><span style="">类型才可以追踪导数</span>, <span style="">用</span><span style="color:#4070a0">`t.requires_grad`</span><span style="">可以查看是否被追踪</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span>    x <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor([<span style="color:#40a070">2</span>,<span style="color:#40a070">3</span>],dtype<span style="color:#666">=</span><span style="color:#007020">float</span>,requires_grad<span style="color:#666">=</span>True)  
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span>    <span style="color:#666">//</span><span style="">对被追踪的</span><span style="color:#4070a0">`Tensor`</span><span style="">赋予一个操作，此时</span><span style="color:#4070a0">`y.grad_fn`</span><span style="color:#666">=&lt;</span>AddBackward <span style="color:#007020">object</span><span style="color:#666">&gt;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span>    <span style="color:#666">//</span>out <span style="color:#666">=</span> <span style="color:#40a070">1</span><span style="color:#666">/</span><span style="color:#40a070">2</span><span style="color:#666">*</span><span style="color:#40a070">3</span><span style="color:#666">*</span>(x<span style="color:#666">+</span><span style="color:#40a070">2</span>)<span style="color:#666">^</span><span style="color:#40a070">2</span>, <span style="">梯度是</span><span style="color:#4070a0">`3x+6`</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span>    y <span style="color:#666">=</span> x <span style="color:#666">+</span> <span style="color:#40a070">2</span>; z <span style="color:#666">=</span> <span style="color:#40a070">3</span><span style="color:#666">*</span>y<span style="color:#666">**</span><span style="color:#40a070">2</span>     
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span>    out <span style="color:#666">=</span> z<span style="color:#666">.</span>mean()                     
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span>    <span style="color:#666">//</span><span style="">被追踪的变量，可以调用</span> <span style="color:#666">.</span>backward() <span style="">并自动计算所有的梯度，得到的梯度都保存在属性</span> <span style="color:#666">.</span>grad <span style="">中</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span>    <span style="color:#666">//</span><span style="">能够改变</span>tensor变量的操作都带有一个后缀<span style="color:#4070a0">`_`</span><span style="">，例如</span>x<span style="color:#666">.</span>copy_(y), x<span style="color:#666">.</span>t_()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span>    out<span style="color:#666">.</span>backward()         <span style="color:#666">//</span><span style="">等于</span>backward(torch<span style="color:#666">.</span>Tensor([<span style="color:#40a070">1</span>])), <span style="">所以</span>out <span style="color:#007020;font-weight:bold">is</span> a single element
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span>    x<span style="color:#666">.</span>grad                 <span style="color:#666">//</span>tensor([<span style="color:#40a070">12.</span>, <span style="color:#40a070">15.</span>]), <span style="">其实就是</span>(<span style="color:#40a070">3</span><span style="color:#666">*</span>x1<span style="color:#666">+</span><span style="color:#40a070">6</span>, <span style="color:#40a070">3</span><span style="color:#666">*</span>x2<span style="color:#666">+</span><span style="color:#40a070">6</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span>    x<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_()         <span style="color:#666">//</span><span style="">对</span>x变量的梯度重新清零      
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span>    <span style="color:#666">//</span><span style="">如果不希望继续追踪某个变量，调用</span><span style="color:#666">.</span>detach()<span style="">或者</span><span style="color:#007020;font-weight:bold">with</span> torch<span style="color:#666">.</span>no_grad()<span style="">防止将来的计算被追踪</span>(<span style="">在评估时用到</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span>    <span style="color:#666">//</span><span style="">如果只想修改</span>tensor的值而不被autograd记录, <span style="">可以对</span> x<span style="color:#666">.</span>data <span style="color:#666">*=</span> <span style="color:#40a070">100</span> <span style="">操作</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span>    x <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(<span style="color:#40a070">1.0</span>, requires_grad<span style="color:#666">=</span>True)          
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span>    y1 <span style="color:#666">=</span> x <span style="color:#666">**</span> <span style="color:#40a070">2</span>            
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span>    y2 <span style="color:#666">=</span> x<span style="color:#666">.</span>detach() <span style="color:#666">**</span> <span style="color:#40a070">3</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span>    y3 <span style="color:#666">=</span> y1<span style="color:#666">+</span> y2; y3<span style="color:#666">.</span>backward()                         <span style="color:#666">//</span>x<span style="color:#666">.</span>grad <span style="color:#666">=</span> <span style="color:#40a070">2</span> <span style="">为什么不是</span><span style="color:#40a070">5</span><span style="">？</span>
</code></pre></div>

<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
当重复 backward 的时候，会得到 RuntimeError: Trying to backward through the graph a second time 这样的错误，为什么？ 
    <br>
    <ul>
<li>
<p>为了减少内存使用，当第一次<code>call .backward()</code>，<code>Torch</code>会从最后一个变量，一直往前追溯求导，一边求导一边把之前的步骤删除了，如果无所谓内存占用，需要重复<code>call .backward()</code>的话，可以<code>call .backward(retain_graph=True)</code>。所有带有<code>requires_grad=True</code>的张量，其梯度<code>.grad</code>都会随着<code>backward() call</code>一直累计</p>
</li>
<li>
<p>如果需要重复<code>call .backward()</code>的话，需要告诉<code>Pytorch</code>不要在<code>backward</code>后释放计算图内存，命令是<code>retain_graph=True</code>，比如下面的例子
$$\begin{align*}
x&amp;=\left(x_{1}=2, x_{2}=3\right)\cr
y&amp;=\left(x_{1}^{2}+3 x_{2}, x_{2}^{2}+2 x_{1}\right) \cr
\frac{\partial y_1}{\partial x_{1}}&amp;=2 x_{1}=4, \frac{\partial y_1}{\partial x_{2}}=3 \cr
\frac{\partial y_2}{\partial x_{1}}&amp;=2, \frac{\partial y_2}{\partial x_{2}}=2 x_{2}=6
\end{align*}$$</p>
</li>
</ul>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    x <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor([[<span style="color:#40a070">2</span>, <span style="color:#40a070">3</span>]], dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float, requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    y <span style="color:#666">=</span> torch<span style="color:#666">.</span>zeros(<span style="color:#40a070">1</span>, <span style="color:#40a070">2</span>)                        
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    y[<span style="color:#40a070">0</span>, <span style="color:#40a070">0</span>] <span style="color:#666">=</span> x[<span style="color:#40a070">0</span>, <span style="color:#40a070">0</span>] <span style="color:#666">**</span> <span style="color:#40a070">2</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span>    y[<span style="color:#40a070">0</span>, <span style="color:#40a070">1</span>] <span style="color:#666">=</span> x[<span style="color:#40a070">0</span>, <span style="color:#40a070">1</span>] <span style="color:#666">**</span> <span style="color:#40a070">3</span> 
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span>    y<span style="color:#666">.</span>backward(torch<span style="color:#666">.</span>tensor([[<span style="color:#40a070">1.</span>,<span style="color:#40a070">0.</span>]]),retain_graph<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">6</span>    jacob <span style="color:#666">=</span> torch<span style="color:#666">.</span>zeros(<span style="color:#40a070">2</span> ,<span style="color:#40a070">2</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">7</span>    j[<span style="color:#40a070">0</span>] <span style="color:#666">=</span> m<span style="color:#666">.</span>grad
</code></pre></div>
  </div>
</aside>



<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
RuntimeError: Expected 4-dimensional input for 4-dimensional weight 只接受mini-batch 的数据，不能是单个样本，比如这里的 nn.Conv2d 网络就只能接受一个4维张量(sample x channel x height x width) 
    <br>
    <ul>
<li>所以如果输入的是单个样本，需要采用<code>input.unsqueeze(0)</code>来扩充一个假的<code>batch</code>维度，输入到<code>nn.Conv2d</code>网络中，同样在比较<code>net(input)</code>和<code>target</code>时，也要记得给<code>target</code>增加一个batch维度<code>(target.view(n_batch,-1))</code>。另外记得先清空梯度缓存<code>net.zero_grad()</code>，然后计算期望梯度进行反向传播<code>y.backward()</code></li>
</ul>

  </div>
</aside>



<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
RuntimeError: grad can be implicitly created only for scalar outputs 当我的output不是 scalar 张量怎么办? 
    <br>
    <ul>
<li>当<code>call loss.backward()</code>时，系统默认<code>loss.backward(torch.Tensor([1]))</code>, 这里参数<code>torch.Tensor([1])</code>代表输出变量增加单位<code>1</code>，所以如果输出变量是多维的，则会报错。</li>
<li><code>Pytorch</code>默认只让标量对张量求导，因此当<code>backward</code>的参数不是标量的时候，系统会先将张量转成标量，下面的例子里，<code>[2,3,4,5]</code>会先把求导对象变成$y&rsquo; = 2y_1 + 3y_2 + 4y_3 + 5y_4$ 然后$\nabla_{x_1} y&rsquo; = 2\times\nabla_{x_1} y_1 = 2\times(2x_1 + 3) = 10$</li>
</ul>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    x <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor([<span style="color:#40a070">1</span>,<span style="color:#40a070">1</span>,<span style="color:#40a070">1</span>,<span style="color:#40a070">1</span>],dtype<span style="color:#666">=</span><span style="color:#007020">float</span>,requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    y <span style="color:#666">=</span> x<span style="color:#666">**</span><span style="color:#40a070">2</span> <span style="color:#666">+</span> <span style="color:#40a070">3</span><span style="color:#666">*</span>x                                      <span style="color:#666">//</span>dy<span style="color:#666">/</span>dx <span style="color:#666">=</span> <span style="color:#40a070">2</span>x <span style="color:#666">+</span> <span style="color:#40a070">3</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    y<span style="color:#666">.</span>backward(torch<span style="color:#666">.</span>tensor([<span style="color:#40a070">2.</span>,<span style="color:#40a070">3.</span>,<span style="color:#40a070">4.</span>,<span style="color:#40a070">5.</span>]))
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span>    x<span style="color:#666">.</span>grad                                              <span style="color:#666">//</span>tensor([ <span style="color:#40a070">10.</span>,  <span style="color:#40a070">15.</span>,  <span style="color:#40a070">20.</span>, <span style="color:#40a070">25.</span>])
</code></pre></div>
  </div>
</aside>

<h2 id="深度学习基础">深度学习基础</h2>


<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
尽量用矢量运算而不要用标量逐个计算, 所以尽量用Torch本身的广播机制 
    <br>
    <div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    a <span style="color:#666">=</span> torch<span style="color:#666">.</span>ones(<span style="color:#40a070">1000</span>); b <span style="color:#666">=</span> torch<span style="color:#666">.</span>ones(<span style="color:#40a070">1000</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    c <span style="color:#666">=</span> torch<span style="color:#666">.</span>zeros(<span style="color:#40a070">1000</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    <span style="color:#007020;font-weight:bold">for</span> i <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(<span style="color:#40a070">1000</span>):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span>        c[i] <span style="color:#666">=</span> a[i] <span style="color:#666">+</span> b[i]                               <span style="color:#666">//</span> <span style="color:#40a070">27</span>ms
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">5</span>    d <span style="color:#666">=</span> a <span style="color:#666">+</span> b                                            <span style="color:#666">//</span>  <span style="color:#40a070">6</span>ms    
</code></pre></div>
  </div>
</aside>

<h3 id="线性回归">线性回归</h3>
<p><figure role="group">
    <a href=" https://i.postimg.cc/V6MjwQRk/image.png" class="img-link">
        <img src="https://i.postimg.cc/V6MjwQRk/image.png" width="80%" title="线性回归模拟数据">
    </a>
    <figcaption>
        模拟数据, $y = 2x_1 -3.4x_2 + 4.2 + \eta(0,0.01)$
    </figcaption>
</figure>
</figure></p>
<div class="expandable-section">
  
    <h3>
  
    <button aria-expanded="false" data-expands="js-expandable-c89eec57b0be334fe44b66bcdb784ef8">
      <span class="expandable-label">详细代码</span>
      <svg aria-hidden="true" focusable="false" viewBox="0 0 70.866142 70.866141">
        <g transform="translate(0 -981.5)">
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="60" width="9.8985" y="987.36" x="30.051" class="up-strut" />
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="10" width="60" y="1012.4" x="5"/>
        </g>
      </svg>
    </button>
  
    </h3>
  
  <div id="js-expandable-c89eec57b0be334fe44b66bcdb784ef8" hidden>
    <div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span>    <span style="color:#60a0b0;font-style:italic">##################### 生成数据 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span>    num_inputs <span style="color:#666">=</span> <span style="color:#40a070">2</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span>    num_examples <span style="color:#666">=</span> <span style="color:#40a070">1000</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span>    true_w <span style="color:#666">=</span> [<span style="color:#40a070">2</span>, <span style="color:#666">-</span><span style="color:#40a070">3.4</span>]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span>    true_b <span style="color:#666">=</span> <span style="color:#40a070">4.2</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span>    features <span style="color:#666">=</span> torch<span style="color:#666">.</span>randn(num_examples, num_inputs, dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float32)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span>    labels <span style="color:#666">=</span> true_w[<span style="color:#40a070">0</span>] <span style="color:#666">*</span> features[:, <span style="color:#40a070">0</span>] <span style="color:#666">+</span> true_w[<span style="color:#40a070">1</span>] <span style="color:#666">*</span> features[:, <span style="color:#40a070">1</span>] <span style="color:#666">+</span> true_b
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span>    labels <span style="color:#666">+=</span> torch<span style="color:#666">.</span>tensor(np<span style="color:#666">.</span>random<span style="color:#666">.</span>normal(<span style="color:#40a070">0</span>, <span style="color:#40a070">0.01</span>, size<span style="color:#666">=</span>labels<span style="color:#666">.</span>size()),dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float32)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span>    <span style="color:#60a0b0;font-style:italic">##################### 定义函数 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">data_iter</span>(batch_size, features, labels):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span>        num_examples <span style="color:#666">=</span> <span style="color:#007020">len</span>(features)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span>        indices <span style="color:#666">=</span> <span style="color:#007020">list</span>(<span style="color:#007020">range</span>(num_examples))
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span>        random<span style="color:#666">.</span>shuffle(indices)                        <span style="color:#666">//</span><span style="">样本的读取顺序是随机的</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span>        <span style="color:#007020;font-weight:bold">for</span> i <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(<span style="color:#40a070">0</span>, num_examples, batch_size):   <span style="color:#666">//</span><span style="">最后一次可能不足一个</span>batch
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span>            j <span style="color:#666">=</span> torch<span style="color:#666">.</span>LongTensor(indices[i: <span style="color:#007020">min</span>(i <span style="color:#666">+</span> batch_size, num_examples)])                            
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span>            <span style="color:#007020;font-weight:bold">yield</span>  features<span style="color:#666">.</span>index_select(<span style="color:#40a070">0</span>, j), labels<span style="color:#666">.</span>index_select(<span style="color:#40a070">0</span>, j)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">linreg</span>(X, w, b):                               <span style="color:#666">//</span><span style="">定义模型</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18</span>        <span style="color:#007020;font-weight:bold">return</span> torch<span style="color:#666">.</span>mm(X, w) <span style="color:#666">+</span> b
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">squared_loss</span>(y_hat, y):                        <span style="color:#666">//</span><span style="">定义损失函数</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20</span>        <span style="color:#007020;font-weight:bold">return</span> (y_hat <span style="color:#666">-</span> y<span style="color:#666">.</span>view(y_hat<span style="color:#666">.</span>size())) <span style="color:#666">**</span> <span style="color:#40a070">2</span> <span style="color:#666">/</span> <span style="color:#40a070">2</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">sgd</span>(params, lr, batch_size):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22</span>        <span style="color:#007020;font-weight:bold">for</span> param <span style="color:#007020;font-weight:bold">in</span> params:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23</span>            param<span style="color:#666">.</span>data <span style="color:#666">-=</span> lr<span style="color:#666">*</span>param<span style="color:#666">.</span>grad<span style="color:#666">/</span>batch_size
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24</span>    w <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(np<span style="color:#666">.</span>random<span style="color:#666">.</span>normal(<span style="color:#40a070">0</span>, <span style="color:#40a070">0.01</span>, (<span style="color:#40a070">2</span>, <span style="color:#40a070">1</span>)), dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float32, requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25</span>    b <span style="color:#666">=</span> torch<span style="color:#666">.</span>zeros(<span style="color:#40a070">1</span>, dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float32, requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26</span>    <span style="color:#60a0b0;font-style:italic">##################### 模型训练 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27</span>    <span style="color:#007020;font-weight:bold">for</span> epoch <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(num_epochs):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28</span>        <span style="color:#007020;font-weight:bold">for</span> X, y <span style="color:#007020;font-weight:bold">in</span> data_iter(batch_size, features, labels):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29</span>            loss <span style="color:#666">=</span> squared_loss(linreg(X,w,b), y)<span style="color:#666">.</span>sum()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30</span>            loss<span style="color:#666">.</span>backward()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31</span>            sgd([w,b], lr, batch_size)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32</span>            w<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_(); b<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33</span>        after_train_loss <span style="color:#666">=</span> squared_loss(linreg(features, w, b), labels)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34</span>        <span style="color:#007020;font-weight:bold">print</span>(<span style="color:#4070a0">&#39;epoch </span><span style="color:#70a0d0;font-style:italic">%d</span><span style="color:#4070a0">, loss </span><span style="color:#70a0d0;font-style:italic">%f</span><span style="color:#4070a0">&#39;</span> <span style="color:#666">%</span> (epoch <span style="color:#666">+</span> <span style="color:#40a070">1</span>, after_train_loss<span style="color:#666">.</span>mean()<span style="color:#666">.</span>item()))
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35</span>    <span style="color:#60a0b0;font-style:italic">################上面的如果用Torch提供的方程写 #################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36</span>    dataset <span style="color:#666">=</span> torch<span style="color:#666">.</span>utils<span style="color:#666">.</span>data<span style="color:#666">.</span>TensorDataset(features, labels)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37</span>    data_iter <span style="color:#666">=</span> Data<span style="color:#666">.</span>DataLoader(dataset, batch_size, shuffle<span style="color:#666">=</span>True, num_workers<span style="color:#666">=</span><span style="color:#40a070">2</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38</span>    <span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">LinearNet</span>(nn<span style="color:#666">.</span>Module):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39</span>        <span style="color:#007020;font-weight:bold">def</span> __init__(self, n_feature):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40</span>            <span style="color:#007020">super</span>(LinearNet, self)<span style="color:#666">.</span>__init__()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41</span>            self<span style="color:#666">.</span>linear <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(n_feature, <span style="color:#40a070">1</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">forward</span>(self, x):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44</span>            y <span style="color:#666">=</span> self<span style="color:#666">.</span>linear(x)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45</span>            <span style="color:#007020;font-weight:bold">return</span> y
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46</span>    net <span style="color:#666">=</span> nn<span style="color:#666">.</span>Sequential(nn<span style="color:#666">.</span>Linear(num_inputs, <span style="color:#40a070">1</span>))     <span style="color:#666">//</span><span style="">中间还可以传入其他层</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47</span>    nn<span style="color:#666">.</span>init<span style="color:#666">.</span>normal_(net[<span style="color:#40a070">0</span>]<span style="color:#666">.</span>weight, mean<span style="color:#666">=</span><span style="color:#40a070">0.0</span>, std<span style="color:#666">=</span><span style="color:#40a070">0.01</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48</span>    nn<span style="color:#666">.</span>init<span style="color:#666">.</span>constant_(net[<span style="color:#40a070">0</span>]<span style="color:#666">.</span>bias, val<span style="color:#666">=</span><span style="color:#40a070">0.0</span>)           <span style="color:#666">//</span><span style="">也可以直接</span>net[<span style="color:#40a070">0</span>]<span style="color:#666">.</span>bias<span style="color:#666">.</span>data<span style="color:#666">.</span>fill_(<span style="color:#40a070">0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49</span>    loss <span style="color:#666">=</span> nn<span style="color:#666">.</span>MSELoss()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50</span>    optimizer <span style="color:#666">=</span> torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(net<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#40a070">0.03</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51</span>    <span style="color:#666">//</span><span style="">也可以为不同网络设置不同学习率，比如</span>[{<span style="color:#4070a0">&#39;params&#39;</span>:subnet<span style="color:#666">.</span>parameters(), <span style="color:#4070a0">&#39;lr&#39;</span>:<span style="color:#40a070">0.01</span>},]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52</span>    <span style="color:#007020;font-weight:bold">for</span> epoch <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(num_epochs):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53</span>        <span style="color:#007020;font-weight:bold">for</span> X,y <span style="color:#007020;font-weight:bold">in</span> data_iter:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54</span>            loss <span style="color:#666">=</span> loss(net(X), y<span style="color:#666">.</span>view(<span style="color:#40a070">1</span>,<span style="color:#666">-</span><span style="color:#40a070">1</span>))          <span style="color:#666">//</span><span style="">加一个</span>batch维度
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55</span>            optimizer<span style="color:#666">.</span>zero_grad()                      <span style="color:#666">//</span><span style="">梯度清零，等价于</span>net<span style="color:#666">.</span>zero_grad()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56</span>            loss<span style="color:#666">.</span>backward()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57</span>            optimizer<span style="color:#666">.</span>step()
</code></pre></div>
  </div>
</div>

<h3 id="softmax回归">Softmax回归</h3>


<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
为什么分类问题要用 softmax 运算而不是 mse_loss 运算 
    <br>
    线性回归模型适用于输出为连续值的情景。当面对分类任务时，我们其实并不要求概率上$P_{pred}$和$P_{true}$一模一样，所以<code>MSE LOSS</code>有些过于苛责了，事实上只需要正确答案的概率大于其他选项的就行。举例而言，下面两种情况
$$\begin{align*}
p_1^{(i)} &amp;=0.2, p_2^{(i)} = 0.2, p_3^{(i)}=0.6  \tag{1}\cr
p_1^{(i)} &amp;=0.0, p_2^{(i)} = 0.4, p_3^{(i)}=0.6  \tag{2}
\end{align*}$$
如果用<code>MSE Loss</code>的话，(1)的loss要比(2)小很多，但其实两者都能分对，没有优劣之分，更应该强调$p_3^{(i)}$的值，所以与其用<code>MSE</code>来区分(1),(2)两种预测分布，不如用<code>cross entropy</code> $H\left(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}\right ) = -\sum_{j=1}^q y_j^{(i)} \log \hat y_j^{(i)}$ 其中带下标的$y_j^{(i)}$非0即1，由于向量$\boldsymbol y^{(i)}=[y_1,y_2,y_3]$中，只有$y_3:=1$正确，其他都是错误选项，因此上式<code>cross entropy</code>可以简化为$H(\boldsymbol y^{(i)}, \boldsymbol {\hat y}^{(i)}) = -\log \hat y_{y^{(i)}}^{(i)}$，即只在乎正确答案的预测概率，但是如果<code>一个instance可以有多个标签的时候，不能这么简化</code>，而且由于
$$\exp(-n\ell(\boldsymbol{\Theta}))=\exp\left(-n \times -\frac{1}{n}  \times \sum_{i=1}^n \log \hat y_{y^{(i)}}^{(i)}\right)=\prod_{i=1}^n \hat y_{y^{(i)}}^{(i)}$$
因此最大化数据集里<code>正确选项(训练集我是知道的)</code>的联合预测概率，等价于最小化<code>cross entropy</code>
  </div>
</aside>

<p><strong>图像分类数据集</strong> (Fashion-MNIST)
用来比较算法之间在模型精度和计算效率上的差别, <code>Fashion-MNIST</code><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> 是一个很小的数据集(几十M)，使用<code>torchvision</code>构建计算机视觉模型</p>
<ol>
<li><code>torchvision.datasets</code>: 一些加载数据的函数及常用的数据集接口；</li>
<li><code>torchvision.models</code>: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；</li>
<li><code>torchvision.transforms</code>: 常用的图片变换，例如裁剪、旋转等；</li>
<li><code>torchvision.utils</code>: 其他的一些有用的方法。
<figure role="group">
    <a href=" /images/3.5_output1.png" class="img-link">
        <img src="/images/3.5_output1.png" width="80%" title="数据内容和标签">
    </a>
    <figcaption>
        训练集前10个样本
    </figcaption>
</figure>
</figure></li>
</ol>
<div class="expandable-section">
  
    <h3>
  
    <button aria-expanded="false" data-expands="js-expandable-627047f6df6e02203c0f480edb33603c">
      <span class="expandable-label">详细代码</span>
      <svg aria-hidden="true" focusable="false" viewBox="0 0 70.866142 70.866141">
        <g transform="translate(0 -981.5)">
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="60" width="9.8985" y="987.36" x="30.051" class="up-strut" />
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="10" width="60" y="1012.4" x="5"/>
        </g>
      </svg>
    </button>
  
    </h3>
  
  <div id="js-expandable-627047f6df6e02203c0f480edb33603c" hidden>
    <div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1</span>    <span style="color:#60a0b0;font-style:italic">##################### 生成数据 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2</span>    <span style="color:#666">//</span><span style="">如果</span>local已有数据<span style="">，不会重复下载，训练集</span> <span style="color:#40a070">60000</span> x (<span style="color:#40a070">28</span>x28 image <span style="color:#666">+</span> label (<span style="color:#40a070">0</span><span style="color:#666">~</span><span style="color:#40a070">9</span>))<span style="">，测试集</span><span style="color:#40a070">10000</span><span style="">个样本</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3</span>    mnist_train <span style="color:#666">=</span> torchvision<span style="color:#666">.</span>datasets<span style="color:#666">.</span>FashionMNIST(root<span style="color:#666">=</span><span style="color:#4070a0">&#39;../Datasets/FashionMNIST&#39;</span>, train<span style="color:#666">=</span>True, download<span style="color:#666">=</span>True, transform<span style="color:#666">=</span>transforms<span style="color:#666">.</span>ToTensor())   
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4</span>    mnist_test <span style="color:#666">=</span> torchvision<span style="color:#666">.</span>datasets<span style="color:#666">.</span>FashionMNIST(root<span style="color:#666">=</span><span style="color:#4070a0">&#39;../Datasets/FashionMNIST&#39;</span>, train<span style="color:#666">=</span>False, download<span style="color:#666">=</span>True, transform<span style="color:#666">=</span>transforms<span style="color:#666">.</span>ToTensor())  
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5</span>    <span style="color:#60a0b0;font-style:italic">##################### 定义函数 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">get_fashion_mnist_labels</span>(labels):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7</span>        text_labels <span style="color:#666">=</span> [<span style="color:#4070a0">&#39;t-shirt&#39;</span>, <span style="color:#4070a0">&#39;trouser&#39;</span>, <span style="color:#4070a0">&#39;pullover&#39;</span>, <span style="color:#4070a0">&#39;dress&#39;</span>, <span style="color:#4070a0">&#39;coat&#39;</span>,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8</span>                    <span style="color:#4070a0">&#39;sandal&#39;</span>, <span style="color:#4070a0">&#39;shirt&#39;</span>, <span style="color:#4070a0">&#39;sneaker&#39;</span>, <span style="color:#4070a0">&#39;bag&#39;</span>, <span style="color:#4070a0">&#39;ankle boot&#39;</span>]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9</span>        <span style="color:#007020;font-weight:bold">return</span> [text_labels[<span style="color:#007020">int</span>(i)] <span style="color:#007020;font-weight:bold">for</span> i <span style="color:#007020;font-weight:bold">in</span> labels]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">show_fashion_mnist</span>(images, labels):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11</span>        d2l<span style="color:#666">.</span>use_svg_display()                          <span style="color:#666">//</span><span style="">用矢量图</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12</span>        _, figs <span style="color:#666">=</span> plt<span style="color:#666">.</span>subplots(<span style="color:#40a070">1</span>, <span style="color:#007020">len</span>(images), figsize<span style="color:#666">=</span>(<span style="color:#40a070">12</span>, <span style="color:#40a070">12</span>))
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13</span>        <span style="color:#007020;font-weight:bold">for</span> f, img, lbl <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">zip</span>(figs, images, labels):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14</span>            f<span style="color:#666">.</span>imshow(img<span style="color:#666">.</span>view((<span style="color:#40a070">28</span>, <span style="color:#40a070">28</span>))<span style="color:#666">.</span>numpy())
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15</span>            f<span style="color:#666">.</span>set_title(lbl)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16</span>            f<span style="color:#666">.</span>axes<span style="color:#666">.</span>get_xaxis()<span style="color:#666">.</span>set_visible(False)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17</span>            f<span style="color:#666">.</span>axes<span style="color:#666">.</span>get_yaxis()<span style="color:#666">.</span>set_visible(False)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18</span>        plt<span style="color:#666">.</span>show()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">softmax</span>(X):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20</span>        <span style="color:#666">//</span>dim<span style="color:#666">=</span><span style="color:#40a070">1</span><span style="">列相加，输出</span>(nx1)<span style="">数据，运用广播机制做矢量运算</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21</span>        X_exp <span style="color:#666">=</span> X<span style="color:#666">.</span>exp(); partition <span style="color:#666">=</span> X_exp<span style="color:#666">.</span>sum(dim<span style="color:#666">=</span><span style="color:#40a070">1</span>, keepdim<span style="color:#666">=</span>True) 
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22</span>        <span style="color:#007020;font-weight:bold">return</span> X_exp <span style="color:#666">/</span> partition                       
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">net</span>(X):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24</span>        <span style="color:#007020;font-weight:bold">return</span> softmax(torch<span style="color:#666">.</span>mm(X<span style="color:#666">.</span>view((<span style="color:#666">-</span><span style="color:#40a070">1</span>, num_inputs)), W) <span style="color:#666">+</span> b)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">cross_entropy</span>(y_hat, y):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26</span>        <span style="color:#666">//</span>dim<span style="color:#666">=</span><span style="color:#40a070">1</span><span style="">按列</span>gather<span style="">，即提取每一行的</span>index<span style="">，</span>y<span style="color:#666">.</span>view(<span style="color:#666">-</span><span style="color:#40a070">1</span>,<span style="color:#40a070">1</span>)<span style="">返回每一行真实标签</span>index
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27</span>        <span style="color:#007020;font-weight:bold">return</span> <span style="color:#666">-</span> torch<span style="color:#666">.</span>log(y_hat<span style="color:#666">.</span>gather(dim<span style="color:#666">=</span><span style="color:#40a070">1</span>, index<span style="color:#666">=</span>y<span style="color:#666">.</span>view(<span style="color:#666">-</span><span style="color:#40a070">1</span>, <span style="color:#40a070">1</span>)))
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">accuracy</span>(yhat, y):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29</span>        <span style="color:#666">//</span>dim<span style="color:#666">=</span><span style="color:#40a070">1</span><span style="">提取每一行最大列的</span>index<span style="">，比较测试集上根据</span>cross<span style="color:#666">-</span>entropy得到的分类准确率
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30</span>        <span style="color:#007020;font-weight:bold">return</span> (yhat<span style="color:#666">.</span>argmax(dim<span style="color:#666">=</span><span style="color:#40a070">1</span>) <span style="color:#666">==</span> y)<span style="color:#666">.</span>float()<span style="color:#666">.</span>mean()<span style="color:#666">.</span>item()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">evaluate_accuracy</span>(data_iter, net):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32</span>        acc_sum, n <span style="color:#666">=</span> <span style="color:#40a070">0.0</span>, <span style="color:#40a070">0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33</span>        <span style="color:#007020;font-weight:bold">for</span> X, y <span style="color:#007020;font-weight:bold">in</span> data_iter:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34</span>            yhat <span style="color:#666">=</span> net(X)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35</span>            acc_sum <span style="color:#666">+=</span> (net(X)<span style="color:#666">.</span>argmax(dim<span style="color:#666">=</span><span style="color:#40a070">1</span>) <span style="color:#666">==</span> y)<span style="color:#666">.</span>float()<span style="color:#666">.</span>sum()<span style="color:#666">.</span>item()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36</span>            n <span style="color:#666">+=</span> y<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37</span>        <span style="color:#007020;font-weight:bold">return</span> acc_sum <span style="color:#666">/</span> n
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38</span>    <span style="color:#60a0b0;font-style:italic">##################### 生成batch ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39</span>    <span style="color:#666">//</span>num_workers <span style="color:#666">=</span> <span style="color:#40a070">0</span> <span style="">表示不用额外的进程加速数据读取，我的读取算力大概只有</span><span style="color:#40a070">1</span><span style="color:#666">/</span><span style="color:#40a070">4</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40</span>    train_iter <span style="color:#666">=</span> torch<span style="color:#666">.</span>utils<span style="color:#666">.</span>data<span style="color:#666">.</span>DataLoader(mnist_train, batch_size<span style="color:#666">=</span>batch_size, shuffle<span style="color:#666">=</span>True, num_workers<span style="color:#666">=</span><span style="color:#40a070">0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41</span>    test_iter <span style="color:#666">=</span> torch<span style="color:#666">.</span>utils<span style="color:#666">.</span>data<span style="color:#666">.</span>DataLoader(mnist_test, batch_size<span style="color:#666">=</span>batch_size, shuffle<span style="color:#666">=</span>False, num_workers<span style="color:#666">=</span><span style="color:#40a070">0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42</span>    <span style="color:#60a0b0;font-style:italic">##################### 模型参数初始化 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43</span>    <span style="color:#666">//</span><span style="">之前的线性模型例子中，</span>W只有2个维度<span style="">，</span>b只有1个<span style="">，这里分别是</span>(<span style="color:#40a070">784</span>x10) <span style="">和</span> (<span style="color:#40a070">10</span>x1)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44</span>    num_inputs, num_outputs <span style="color:#666">=</span> <span style="color:#40a070">784</span>, <span style="color:#40a070">10</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45</span>    W <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(np<span style="color:#666">.</span>random<span style="color:#666">.</span>normal(<span style="color:#40a070">0</span>, <span style="color:#40a070">0.01</span>, (num_inputs, num_outputs)), dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float, requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46</span>    b <span style="color:#666">=</span> torch<span style="color:#666">.</span>zeros(num_outputs, dtype<span style="color:#666">=</span>torch<span style="color:#666">.</span>float, requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47</span>    <span style="color:#60a0b0;font-style:italic">##################### 模型训练 ############################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48</span>    <span style="color:#007020;font-weight:bold">for</span> epoch <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(<span style="color:#40a070">5</span>):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49</span>        train_l_sum, train_acc_sum, n <span style="color:#666">=</span> <span style="color:#40a070">0.0</span>, <span style="color:#40a070">0.0</span>, <span style="color:#40a070">0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50</span>        <span style="color:#007020;font-weight:bold">for</span> X,y <span style="color:#007020;font-weight:bold">in</span> train_iter:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51</span>            yhat <span style="color:#666">=</span> net(X)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52</span>            loss <span style="color:#666">=</span> cross_entropy(yhat, y)<span style="color:#666">.</span>sum()      
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53</span>            loss<span style="color:#666">.</span>backward()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54</span>            d2l<span style="color:#666">.</span>sgd(params<span style="color:#666">=</span>[W, b], lr<span style="color:#666">=</span><span style="color:#40a070">0.1</span>, batch_size<span style="color:#666">=</span><span style="color:#40a070">256</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55</span>            W<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_(); b<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56</span>            train_l_sum <span style="color:#666">+=</span> loss<span style="color:#666">.</span>item()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57</span>            train_acc_sum <span style="color:#666">+=</span> (y_hat<span style="color:#666">.</span>argmax(dim<span style="color:#666">=</span><span style="color:#40a070">1</span>) <span style="color:#666">==</span> y)<span style="color:#666">.</span>sum()<span style="color:#666">.</span>item()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58</span>            n <span style="color:#666">+=</span> y<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59</span>        test_acc <span style="color:#666">=</span> evaluate_accuracy(test_iter, net)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60</span>        <span style="color:#666">//</span>epoch <span style="color:#40a070">1</span>, loss <span style="color:#40a070">0.7873</span>, train acc <span style="color:#40a070">0.003</span>, test acc <span style="color:#40a070">0.793</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61</span>        <span style="color:#666">//</span>epoch <span style="color:#40a070">5</span>, loss <span style="color:#40a070">0.4859</span>, train acc <span style="color:#40a070">0.003</span>, test acc <span style="color:#40a070">0.823</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62</span>    <span style="color:#60a0b0;font-style:italic">################上面的如果用Torch提供的方程写 #################</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63</span>    batch_size, num_inputs, num_outputs <span style="color:#666">=</span> <span style="color:#40a070">256</span>, <span style="color:#40a070">784</span>, <span style="color:#40a070">10</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64</span>    train_iter, test_iter <span style="color:#666">=</span> d2l<span style="color:#666">.</span>load_data_fashion_mnist(batch_size)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65</span>    <span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">Flatten</span>(nn<span style="color:#666">.</span>Module):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">forward</span>(self, x):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67</span>            <span style="color:#007020;font-weight:bold">return</span> x<span style="color:#666">.</span>view(x<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>], <span style="color:#666">-</span><span style="color:#40a070">1</span>)             <span style="color:#666">//</span><span style="">只保留</span>batch维度后面压缩
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68</span>    net <span style="color:#666">=</span> nn<span style="color:#666">.</span>Sequential(Flatten(),nn<span style="color:#666">.</span>Linear(num_inputs, num_outputs))
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69</span>    nn<span style="color:#666">.</span>init<span style="color:#666">.</span>normal_(net[<span style="color:#40a070">1</span>]<span style="color:#666">.</span>weight, mean<span style="color:#666">=</span><span style="color:#40a070">0.0</span>, std<span style="color:#666">=</span><span style="color:#40a070">0.01</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70</span>    nn<span style="color:#666">.</span>init<span style="color:#666">.</span>constant_(net[<span style="color:#40a070">1</span>]<span style="color:#666">.</span>bias, val<span style="color:#666">=</span><span style="color:#40a070">0.0</span>)         
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71</span>    loss <span style="color:#666">=</span> nn<span style="color:#666">.</span>CrossEntropyLoss()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72</span>    optimizer <span style="color:#666">=</span> torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(net<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#40a070">0.1</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73</span>    <span style="color:#007020;font-weight:bold">for</span> epoch <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(<span style="color:#40a070">5</span>):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74</span>        train_l_sum, train_acc_sum, n <span style="color:#666">=</span> <span style="color:#40a070">0.0</span>, <span style="color:#40a070">0.0</span>, <span style="color:#40a070">0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75</span>        <span style="color:#007020;font-weight:bold">for</span> X,y <span style="color:#007020;font-weight:bold">in</span> train_iter:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76</span>            yhat <span style="color:#666">=</span> net(X)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77</span>            l <span style="color:#666">=</span> loss(yhat, y)<span style="color:#666">.</span>sum()   
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78</span>            optimizer<span style="color:#666">.</span>zero_grad()                      
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79</span>            l<span style="color:#666">.</span>backward()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80</span>            optimizer<span style="color:#666">.</span>step()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81</span>        <span style="color:#666">//</span>epoch <span style="color:#40a070">1</span>, loss <span style="color:#40a070">0.0031</span>, train acc <span style="color:#40a070">0.751</span>, test acc <span style="color:#40a070">0.790</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">82</span>        <span style="color:#666">//</span>epoch <span style="color:#40a070">5</span>, loss <span style="color:#40a070">0.0019</span>, train acc <span style="color:#40a070">0.837</span>, test acc <span style="color:#40a070">0.824</span>
</code></pre></div>
  </div>
</div>



<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
关于.data 和 .cpu().data 的说明 
    <br>
    <ul>
<li><code>.cuda()</code>会把 <code>autograd.Variable</code> 和 <code>torch.Tensor</code> 搬到GPU上，比较消耗时间，能去掉就去掉</li>
<li>什么时候需要用到<code>.clone()</code>操作</li>
<li>哪些运算要放在CPU上</li>
<li>现在有好多RL的研究范式，应该怎么学习 <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://winderresearch.com/a-comparison-of-reinforcement-learning-frameworks-dopamine-rllib-keras-rl-coach-trfl-tensorforce-coach-and-more/">A Comparison of Reinforcement Learning Frameworks: Dopamine, RLLib, Keras-RL, Coach, TRFL, Tensorforce, Coach and more</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

  </div>
</aside>

<p><strong>构建轻量化强化学习</strong> (LightningModule)
Lightning提供了很多接口和可重写的函数，以获得最大的灵活性。以<code>DQN</code>为例子，一个轻量化的算法包含以下几个部分</p>
<ul>
<li>模型：用来逼近Q值的神经网络 (线性MLP网络，没有使用复杂的卷积和递归神经网络)</li>
<li>重播缓冲区：这是我们智能体的内存，用于存储以前的经验 (基于Lapins重播缓冲区，简洁和快) 以及 可迭代数据集 (因为强化学习并不提供数据集，而是生成采样)</li>
<li>智能体：智能体本身就是与环境和重播缓冲区交互的东西 (定义 <code>get_action</code>, <code>play_step</code> 和 <code>reset</code> 三种方法)</li>
<li>Lightning模块：处理智能体的所有训练；我们需要定义<code>forward</code>, <code>optimizer</code>, <code>train_dataloader</code> 和 <code>train_step</code> 四个关键方法</li>
</ul>
<div class="expandable-section">
  
    <h3>
  
    <button aria-expanded="false" data-expands="js-expandable-88e2e9b91289814e9be5399ffd0d24c7">
      <span class="expandable-label">详细代码</span>
      <svg aria-hidden="true" focusable="false" viewBox="0 0 70.866142 70.866141">
        <g transform="translate(0 -981.5)">
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="60" width="9.8985" y="987.36" x="30.051" class="up-strut" />
          <rect style="stroke-width:0;fill:currentColor" ry="5" height="10" width="60" y="1012.4" x="5"/>
        </g>
      </svg>
    </button>
  
    </h3>
  
  <div id="js-expandable-88e2e9b91289814e9be5399ffd0d24c7" hidden>
    <div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  1</span>    <span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">DQNLightning</span>(pl<span style="color:#666">.</span>LightningModule):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  2</span>        <span style="color:#4070a0">&#34;&#34;&#34; Basic DQN Model &#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  3</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  4</span>        <span style="color:#007020;font-weight:bold">def</span> __init__(self, hparams: argparse<span style="color:#666">.</span>Namespace) <span style="color:#666">-&gt;</span> None:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  5</span>            <span style="color:#007020">super</span>()<span style="color:#666">.</span>__init__()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  6</span>            self<span style="color:#666">.</span>hparams <span style="color:#666">=</span> hparams
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  7</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  8</span>            self<span style="color:#666">.</span>env <span style="color:#666">=</span> gym<span style="color:#666">.</span>make(self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>env)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">  9</span>            obs_size <span style="color:#666">=</span> self<span style="color:#666">.</span>env<span style="color:#666">.</span>observation_space<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 10</span>            n_actions <span style="color:#666">=</span> self<span style="color:#666">.</span>env<span style="color:#666">.</span>action_space<span style="color:#666">.</span>n
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 11</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 12</span>            self<span style="color:#666">.</span>net <span style="color:#666">=</span> DQN(obs_size, n_actions)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 13</span>            self<span style="color:#666">.</span>target_net <span style="color:#666">=</span> DQN(obs_size, n_actions)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 14</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 15</span>            self<span style="color:#666">.</span>buffer <span style="color:#666">=</span> ReplayBuffer(self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>replay_size)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 16</span>            self<span style="color:#666">.</span>agent <span style="color:#666">=</span> Agent(self<span style="color:#666">.</span>env, self<span style="color:#666">.</span>buffer)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 17</span>            
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 18</span>            self<span style="color:#666">.</span>total_reward <span style="color:#666">=</span> <span style="color:#40a070">0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 19</span>            self<span style="color:#666">.</span>episode_reward <span style="color:#666">=</span> <span style="color:#40a070">0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 20</span>            
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 21</span>            self<span style="color:#666">.</span>populate(self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>warm_start_steps)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 22</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 23</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">populate</span>(self, steps: <span style="color:#007020">int</span> <span style="color:#666">=</span> <span style="color:#40a070">1000</span>) <span style="color:#666">-&gt;</span> None:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 24</span>            <span style="color:#4070a0">&#34;&#34;&#34;
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 25</span><span style="color:#4070a0">            Carries out several random steps through the environment to initially fill
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 26</span><span style="color:#4070a0">            up the replay buffer with experiences
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 27</span><span style="color:#4070a0">            Args:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 28</span><span style="color:#4070a0">                steps: number of random steps to populate the buffer with
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 29</span><span style="color:#4070a0">            &#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 30</span>            <span style="color:#007020;font-weight:bold">for</span> i <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(steps):
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 31</span>                self<span style="color:#666">.</span>agent<span style="color:#666">.</span>play_step(self<span style="color:#666">.</span>net, epsilon<span style="color:#666">=</span><span style="color:#40a070">1.0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 32</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 33</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">forward</span>(self, x: torch<span style="color:#666">.</span>Tensor) <span style="color:#666">-&gt;</span> torch<span style="color:#666">.</span>Tensor:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 34</span>            <span style="color:#4070a0">&#34;&#34;&#34;
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 35</span><span style="color:#4070a0">            Passes in a state x through the network and gets the q_values of each action as an output
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 36</span><span style="color:#4070a0">            Args:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 37</span><span style="color:#4070a0">                x: environment state
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 38</span><span style="color:#4070a0">            Returns:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 39</span><span style="color:#4070a0">                q values
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 40</span><span style="color:#4070a0">            &#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 41</span>            output <span style="color:#666">=</span> self<span style="color:#666">.</span>net(x)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 42</span>            <span style="color:#007020;font-weight:bold">return</span> output
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 43</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 44</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">dqn_mse_loss</span>(self, batch: Tuple[torch<span style="color:#666">.</span>Tensor, torch<span style="color:#666">.</span>Tensor]) <span style="color:#666">-&gt;</span> torch<span style="color:#666">.</span>Tensor:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 45</span>            <span style="color:#4070a0">&#34;&#34;&#34;
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 46</span><span style="color:#4070a0">            Calculates the mse loss using a mini batch from the replay buffer
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 47</span><span style="color:#4070a0">            Args:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 48</span><span style="color:#4070a0">                batch: current mini batch of replay data
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 49</span><span style="color:#4070a0">            Returns:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 50</span><span style="color:#4070a0">                loss
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 51</span><span style="color:#4070a0">            &#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 52</span>            states, actions, rewards, dones, next_states <span style="color:#666">=</span> batch
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 53</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 54</span>            state_action_values <span style="color:#666">=</span> self<span style="color:#666">.</span>net(states)<span style="color:#666">.</span>gather(<span style="color:#40a070">1</span>, actions<span style="color:#666">.</span>unsqueeze(<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">.</span>squeeze(<span style="color:#666">-</span><span style="color:#40a070">1</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 55</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 56</span>            <span style="color:#007020;font-weight:bold">with</span> torch<span style="color:#666">.</span>no_grad():
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 57</span>                next_state_values <span style="color:#666">=</span> self<span style="color:#666">.</span>target_net(next_states)<span style="color:#666">.</span>max(<span style="color:#40a070">1</span>)[<span style="color:#40a070">0</span>]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 58</span>                next_state_values[dones] <span style="color:#666">=</span> <span style="color:#40a070">0.0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 59</span>                next_state_values <span style="color:#666">=</span> next_state_values<span style="color:#666">.</span>detach()
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 60</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 61</span>            expected_state_action_values <span style="color:#666">=</span> next_state_values <span style="color:#666">*</span> self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>gamma <span style="color:#666">+</span> rewards
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 62</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 63</span>            <span style="color:#007020;font-weight:bold">return</span> nn<span style="color:#666">.</span>MSELoss()(state_action_values, expected_state_action_values)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 64</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 65</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">training_step</span>(self, batch: Tuple[torch<span style="color:#666">.</span>Tensor, torch<span style="color:#666">.</span>Tensor], nb_batch) <span style="color:#666">-&gt;</span> OrderedDict:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 66</span>            <span style="color:#4070a0">&#34;&#34;&#34;
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 67</span><span style="color:#4070a0">            Carries out a single step through the environment to update the replay buffer.
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 68</span><span style="color:#4070a0">            Then calculates loss based on the minibatch recieved
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 69</span><span style="color:#4070a0">            Args:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 70</span><span style="color:#4070a0">                batch: current mini batch of replay data
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 71</span><span style="color:#4070a0">                nb_batch: batch number
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 72</span><span style="color:#4070a0">            Returns:
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 73</span><span style="color:#4070a0">                Training loss and log metrics
</span><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 74</span><span style="color:#4070a0">            &#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 75</span>            device <span style="color:#666">=</span> self<span style="color:#666">.</span>get_device(batch)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 76</span>            epsilon <span style="color:#666">=</span> <span style="color:#007020">max</span>(self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>eps_end, self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>eps_start <span style="color:#666">-</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 77</span>                        self<span style="color:#666">.</span>global_step <span style="color:#666">+</span> <span style="color:#40a070">1</span> <span style="color:#666">/</span> self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>eps_last_frame)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 78</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 79</span>            <span style="color:#60a0b0;font-style:italic"># step through environment with agent</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 80</span>            reward, done <span style="color:#666">=</span> self<span style="color:#666">.</span>agent<span style="color:#666">.</span>play_step(self<span style="color:#666">.</span>net, epsilon, device)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 81</span>            self<span style="color:#666">.</span>episode_reward <span style="color:#666">+=</span> reward
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 82</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 83</span>            <span style="color:#60a0b0;font-style:italic"># calculates training loss</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 84</span>            loss <span style="color:#666">=</span> self<span style="color:#666">.</span>dqn_mse_loss(batch)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 85</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 86</span>            <span style="color:#007020;font-weight:bold">if</span> self<span style="color:#666">.</span>trainer<span style="color:#666">.</span>use_dp <span style="color:#007020;font-weight:bold">or</span> self<span style="color:#666">.</span>trainer<span style="color:#666">.</span>use_ddp2:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 87</span>                loss <span style="color:#666">=</span> loss<span style="color:#666">.</span>unsqueeze(<span style="color:#40a070">0</span>)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 88</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 89</span>            <span style="color:#007020;font-weight:bold">if</span> done:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 90</span>                self<span style="color:#666">.</span>total_reward <span style="color:#666">=</span> self<span style="color:#666">.</span>episode_reward
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 91</span>                self<span style="color:#666">.</span>episode_reward <span style="color:#666">=</span> <span style="color:#40a070">0</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 92</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 93</span>            <span style="color:#60a0b0;font-style:italic"># Soft update of target network</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 94</span>            <span style="color:#007020;font-weight:bold">if</span> self<span style="color:#666">.</span>global_step <span style="color:#666">%</span> self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>sync_rate <span style="color:#666">==</span> <span style="color:#40a070">0</span>:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 95</span>                self<span style="color:#666">.</span>target_net<span style="color:#666">.</span>load_state_dict(self<span style="color:#666">.</span>net<span style="color:#666">.</span>state_dict())
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 96</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 97</span>            log <span style="color:#666">=</span> {<span style="color:#4070a0">&#39;total_reward&#39;</span>: torch<span style="color:#666">.</span>tensor(self<span style="color:#666">.</span>total_reward)<span style="color:#666">.</span>to(device),
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 98</span>                <span style="color:#4070a0">&#39;reward&#39;</span>: torch<span style="color:#666">.</span>tensor(reward)<span style="color:#666">.</span>to(device),
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 99</span>                <span style="color:#4070a0">&#39;steps&#39;</span>: torch<span style="color:#666">.</span>tensor(self<span style="color:#666">.</span>global_step)<span style="color:#666">.</span>to(device)}
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">100</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">101</span>            <span style="color:#007020;font-weight:bold">return</span> OrderedDict({<span style="color:#4070a0">&#39;loss&#39;</span>: loss, <span style="color:#4070a0">&#39;log&#39;</span>: log, <span style="color:#4070a0">&#39;progress_bar&#39;</span>: log})
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">102</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">103</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">configure_optimizers</span>(self) <span style="color:#666">-&gt;</span> List[Optimizer]:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">104</span>            <span style="color:#4070a0">&#34;&#34;&#34; Initialize Adam optimizer&#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">105</span>            optimizer <span style="color:#666">=</span> optim<span style="color:#666">.</span>Adam(self<span style="color:#666">.</span>net<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span>self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>lr)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">106</span>            <span style="color:#007020;font-weight:bold">return</span> [optimizer]
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">107</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">108</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">train_dataloader</span>(self) <span style="color:#666">-&gt;</span> DataLoader:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">109</span>            <span style="color:#4070a0">&#34;&#34;&#34;Initialize the Replay Buffer dataset used for retrieving experiences&#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">110</span>            dataset <span style="color:#666">=</span> RLDataset(self<span style="color:#666">.</span>buffer, self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>episode_length)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">111</span>            dataloader <span style="color:#666">=</span> DataLoader(dataset<span style="color:#666">=</span>dataset,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">112</span>                                    batch_size<span style="color:#666">=</span>self<span style="color:#666">.</span>hparams<span style="color:#666">.</span>batch_size,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">113</span>                                    )
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">114</span>            <span style="color:#007020;font-weight:bold">return</span> dataloader
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">115</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">116</span>        <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">get_device</span>(self, batch) <span style="color:#666">-&gt;</span> <span style="color:#007020">str</span>:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">117</span>            <span style="color:#4070a0">&#34;&#34;&#34;Retrieve device currently being used by minibatch&#34;&#34;&#34;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">118</span>            <span style="color:#007020;font-weight:bold">return</span> batch[<span style="color:#40a070">0</span>]<span style="color:#666">.</span>device<span style="color:#666">.</span>index <span style="color:#007020;font-weight:bold">if</span> self<span style="color:#666">.</span>on_gpu <span style="color:#007020;font-weight:bold">else</span> <span style="color:#4070a0">&#39;cpu&#39;</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">119</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">120</span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">main</span>(hparams) <span style="color:#666">-&gt;</span> None:
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">121</span>        model <span style="color:#666">=</span> DQNLightning(hparams)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">122</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">123</span>        trainer <span style="color:#666">=</span> pl<span style="color:#666">.</span>Trainer(
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">124</span>            gpus<span style="color:#666">=</span><span style="color:#40a070">1</span>,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">125</span>            distributed_backend<span style="color:#666">=</span><span style="color:#4070a0">&#39;dp&#39;</span>,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">126</span>            max_epochs<span style="color:#666">=</span><span style="color:#40a070">10000</span>,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">127</span>            early_stop_callback<span style="color:#666">=</span>False,
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">128</span>            val_check_interval<span style="color:#666">=</span><span style="color:#40a070">100</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">129</span>        )
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">130</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">131</span>        trainer<span style="color:#666">.</span>fit(model)
</code></pre></div>
  </div>
</div>

<h2 id="深度学习进阶">深度学习进阶</h2>
<h3 id="variable-detach-与-detach_">Variable detach 与 detach_</h3>


<aside aria-label="note" class="note">
  <div>
    <svg class="sign" aria-hidden="true" viewBox="0 0 41.667306 41.66729" focusable="false">
      <use xlink:href="#info"></use>
    </svg>
    
detach()方法的作用 
    <br>
    <p>所有<code>requires_grad = True</code>的变量参与的<code>operation node</code>都会被记录在图里，当一个变量<code>detach</code>，那么这个变量之后连接的所有<code>operation node</code>都不会出现在图里了。比如下面这个例子中，因为<code>z = x.detach()**3</code>，从源头开始图里就没有另一个关于<code>x</code>的分支了</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1</span>    x<span style="color:#666">=</span>torch<span style="color:#666">.</span>ones(<span style="color:#40a070">10</span>, requires_grad<span style="color:#666">=</span>True)
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2</span>    y<span style="color:#666">=</span>x<span style="color:#666">**</span><span style="color:#40a070">2</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3</span>    z<span style="color:#666">=</span>x<span style="color:#666">.</span>detach()<span style="color:#666">**</span><span style="color:#40a070">3</span>   <span style="color:#666">//</span><span style="">如果不加</span>detach()<span style="">就是左图，不加</span>detach()<span style="">，关于</span>x的导数就是[<span style="color:#40a070">5</span>]<span style="color:#666">*</span><span style="color:#40a070">10</span>, <span style="">加了</span>detach()<span style="">，导数就只有</span>y分支也就是[<span style="color:#40a070">2</span>]<span style="color:#666">*</span><span style="color:#40a070">10</span>
<span style="margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">4</span>    r<span style="color:#666">=</span>(y<span style="color:#666">+</span>z)<span style="color:#666">.</span>sum()    
</code></pre></div><p><img src="https://i.postimg.cc/Dfps1hT0/image.png" alt="" title="detach()效果"></p>

  </div>
</aside>

<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Xiao, H., Rasul, K., &amp; Vollgraf, R. (2017). <a href="https://arxiv.org/abs/1708.07747">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</a>. arXiv preprint arXiv:1708.07747. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

	

<a href="#" id="back-to-top" class="back-to-top" style="display: inline;">Back to Top</a>

<script>
  var link = document.getElementById("back-to-top");
  var amountScrolled = 1000;

  window.addEventListener('scroll', function(e) {
      if ( window.pageYOffset > amountScrolled ) {
          link.classList.add('show');
      } else {
          link.className = 'back-to-top';
      }
  });

<!-- Scrolls to Top -->
  link.addEventListener('click', function(e) {
      e.preventDefault();

      var distance = 0 - window.pageYOffset;
      var increments = distance/(500/16);
      function animateScroll() {
          window.scrollBy(0, increments);
          if (window.pageYOffset <= document.body.offsetTop) {
              clearInterval(runAnimation);
          }
      };
      
      var runAnimation = setInterval(animateScroll, 16);
  });
</script>

<style>
  .back-to-top {
    background: #111;
    color: #fefefe;
    opacity: 0;
    transition: opacity .6s ease-in-out;
    z-index: 999;
    position: fixed;
    right: 30px;
    bottom: 30px;
    width: auto;
    height: auto;
    box-sizing: border-box;
    border-radius: 0.4em;
    word-wrap: normal !important;
  }

  a.back-to-top {
    font-weight: bold;
    letter-spacing: 0px;
    font-size: 0.75rem;
    font-family: inherit;
    text-transform: uppercase;
    text-align: center;
    padding: 0.65em 0.55em;
  }

  .back-to-top:hover, .back-to-top:focus, .back-to-top:visited {
    color: #fefefe;
    border-bottom: none;
  }

  .back-to-top.show {
    opacity: 1;
  }
</style>


  </main>
  <div id="disqus-container">
  
</div>


          <footer role="contentinfo">
  <div>
    <label for="themer">
      dark theme: <input type="checkbox" id="themer" class="vh">
      <span aria-hidden="true"></span>
    </label>
  </div>
  
    © 2020
  
</footer>

        </div>
      </div>
    </div>
    <script src="https://dennislblog.github.io/js/prism.js"></script>
<script src="https://dennislblog.github.io/js/dom-scripts.js"></script>
    
  

  </body>
</html>
